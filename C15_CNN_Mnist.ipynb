{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C15_CNN_Mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyam-Khokhariya/ML-Python/blob/master/C15_CNN_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNTx8iUSTfuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnuwelj_Uc4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydODJrWOVEYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist=np.load(\"mnist_scaled.npz\")\n",
        "X_train,y_train,X_test,y_test=[mnist[f] for f in mnist.files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzSfqnh1V9fx",
        "colab_type": "code",
        "outputId": "622a1e13-b1b1-43b2-81f9-a09be0537943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784) (60000,)\n",
            "(10000, 784) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjwgN4srWJx_",
        "colab_type": "code",
        "outputId": "cb663ef1-b2d6-42c3-e94c-8b3f1e063a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "X_valid,y_valid=X_train[50000:,:],y_train[50000:]\n",
        "X_train,y_train=X_train[:50000,:],y_train[:50000]\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_valid.shape,y_valid.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (50000,)\n",
            "(10000, 784) (10000,)\n",
            "(10000, 784) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RNS7V-9W0w7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(X,y,batch_size=64,shuffle=False,random_seed=None):\n",
        "  idx=np.arange(y.shape[0])\n",
        "  if shuffle:\n",
        "    rng=np.random.RandomState(random_seed)\n",
        "    rng.shuffle(idx)\n",
        "    X=X[idx]\n",
        "    y=y[idx]\n",
        "  for i in range(0,X.shape[0],batch_size):\n",
        "    yield (X[i:i+batch_size,:],y[i:i+batch_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL2KDN2hLnkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_val=np.mean(X_train,axis=0)\n",
        "std_val=np.std(X_train)\n",
        "\n",
        "X_train_centered=(X_train-mean_val)/std_val\n",
        "X_valid_centered=(X_valid-mean_val)/std_val\n",
        "X_test_centered=(X_test-mean_val)/std_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI9WqXDBMk1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(input_tensor,name,\n",
        "               kernel_size,n_output_channels,\n",
        "               padding_mode=\"SAME\",strides=(1,1,1,1)):\n",
        "  with tf.variable_scope(name):\n",
        "    input_shape=input_tensor.get_shape().as_list()\n",
        "    n_input_channels=input_shape[-1]\n",
        "    weight_shape=list(kernel_size)+[n_input_channels,n_output_channels]\n",
        "    print(weight_shape)\n",
        "    weights=tf.get_variable(name=\"_weights\",shape=weight_shape)\n",
        "    print(\"Weights : \",weights)\n",
        "    biases=tf.get_variable(name=\"_biases\",initializer=tf.zeros(shape=[n_output_channels]))\n",
        "    print(\"Biases : \",biases)\n",
        "    \n",
        "    conv=tf.nn.conv2d(input=input_tensor,filter=weights,strides=strides,padding=padding_mode)\n",
        "    \n",
        "    print(\"Conv : \",conv)\n",
        "    \n",
        "    conv=tf.nn.bias_add(conv,biases,name=\"net_pre-activation\")\n",
        "    \n",
        "    print(\"Conv Bias Addition :\",conv)\n",
        "    \n",
        "    conv=tf.nn.relu(conv,name=\"Activation\")\n",
        "    \n",
        "    print(\"ACtivated Conv : \",conv)\n",
        "    \n",
        "    return conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxV0fKueQR6G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fa47fab8-ce28-4a14-d170-e9a76356e722"
      },
      "source": [
        "g=tf.Graph()\n",
        "with g.as_default():\n",
        "  x=tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
        "  conv_layer(x,name=\"conv_test\",kernel_size=(3,3),n_output_channels=32)\n",
        "\n",
        "del g,x"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 3, 1, 32]\n",
            "Weights :  <tf.Variable 'conv_test/_weights:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n",
            "Biases :  <tf.Variable 'conv_test/_biases:0' shape=(32,) dtype=float32_ref>\n",
            "Conv :  Tensor(\"conv_test/Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "Conv Bias Addition : Tensor(\"conv_test/net_pre-activation:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "ACtivated Conv :  Tensor(\"conv_test/Activation:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTZnAn3tQzfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc_layer(input_tensor,name,n_output_units,activation_fn=None):\n",
        "  with tf.variable_scope(name):\n",
        "    input_shape=input_tensor.get_shape().as_list()[1:]\n",
        "    n_input_units=np.prod(input_shape)\n",
        "    if len(input_shape)>1:\n",
        "      input_tensor=tf.reshape(input_tensor,shape=(-1,n_input_units))\n",
        "    weights_shape=[n_input_units,n_output_units]\n",
        "    weights=tf.get_variable(name=\"_weights\",shape=weights_shape)\n",
        "    print(\"Weights : \",weights)\n",
        "    \n",
        "    biases=tf.get_variable(name=\"_biases\",initializer=tf.zeros(shape=[n_output_units]))\n",
        "    print(\"Biases : \",biases)\n",
        "    \n",
        "    layer=tf.matmul(input_tensor,weights)\n",
        "    print(\"Layer : \",layer)\n",
        "    \n",
        "    layer=tf.nn.bias_add(layer,biases,name=\"net_pre-activation\")\n",
        "    print(\"Biased added layer : \",layer)\n",
        "    \n",
        "    if activation_fn is None:\n",
        "      return layer\n",
        "    \n",
        "    layer=activation_fn(layer,name=\"activation\")\n",
        "    print(\"1 layer output : \",layer)\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsW_DRKaUg7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dc4a6df5-bf3f-40f7-b4eb-9cd2d561a18a"
      },
      "source": [
        "g1=tf.Graph()\n",
        "with g1.as_default():\n",
        "  x=tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
        "  fc_layer(x,name=\"fctest\",n_output_units=32,activation_fn=tf.nn.relu)\n",
        "del g1,x"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights :  <tf.Variable 'fctest/_weights:0' shape=(784, 32) dtype=float32_ref>\n",
            "Biases :  <tf.Variable 'fctest/_biases:0' shape=(32,) dtype=float32_ref>\n",
            "Layer :  Tensor(\"fctest/MatMul:0\", shape=(?, 32), dtype=float32)\n",
            "Biased added layer :  Tensor(\"fctest/net_pre-activation:0\", shape=(?, 32), dtype=float32)\n",
            "1 layer output :  Tensor(\"fctest/activation:0\", shape=(?, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KChM6DBbU4t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cnn():\n",
        "  tf_x=tf.placeholder(tf.float32,shape=[None,784],name=\"tf_x\")\n",
        "  tf_y=tf.placeholder(tf.int32,shape=[None],name=\"tf_y\")\n",
        "  \n",
        "  tf_x_image=tf.reshape(tf_x,shape=[-1,28,28,1],name=\"tf_x_reshaped\")\n",
        "  tf_y_onehot=tf.one_hot(indices=tf_y,depth=10,dtype=tf.float32,name=\"tf_y_onehot\")\n",
        "  \n",
        "  #1st Layer:Conv1\n",
        "  print(\"-----Building 1st Layer-----\\n\")\n",
        "  h1=conv_layer(tf_x_image,name=\"conv_1\",kernel_size=(5,5),padding_mode=\"VALID\",n_output_channels=32)\n",
        "   \n",
        "  #MAX POOLING\n",
        "  h1_pool=tf.nn.max_pool(h1,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "  \n",
        "  #2nd Layer:Conv2\n",
        "  print(\"\\n-----Building 2nd Layer-----\\n\")\n",
        "  h2=conv_layer(h1_pool,name=\"conv_2\",kernel_size=(5,5),padding_mode=\"VALID\",n_output_channels=64)\n",
        "  \n",
        "  #MAX POOLING\n",
        "  h2_pool=tf.nn.max_pool(h2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
        "  \n",
        "  #3rd Layer:Fully Connected\n",
        "  print(\"\\n-----Building 3rd Layer-----\\n\")\n",
        "  h3=fc_layer(h2_pool,name=\"fc_3\",n_output_units=1024,activation_fn=tf.nn.relu)\n",
        "  \n",
        "  #DROPOUT\n",
        "  keep_prob=tf.placeholder(tf.float32,name=\"fc_keep_prob\")\n",
        "  h3_drop=tf.nn.dropout(h3,keep_prob=keep_prob,name=\"dropout_layer\")\n",
        "  \n",
        "  ##4th Layer:Fully Connected (Linear Activation)\n",
        "  print(\"\\n-----Building 4th Layer-----\\n\")\n",
        "  h4=fc_layer(h3_drop,name=\"fc_4\",n_output_units=10,activation_fn=\"None\")\n",
        "  \n",
        "  ##Prediction\n",
        "  prediction={\n",
        "      'probabilities':tf.nn.softmax(h4,name=\"probabilities\"),\n",
        "      'labels':tf.cast(tf.argmax(h4,axis=1),tf.int32,name=\"labels\")\n",
        "  }\n",
        "  \n",
        "  ##Visualize graph with tensorboard\n",
        "  \n",
        "  ##LossFunction and Optimization\n",
        "  cross_entropy_loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h4,labels=tf_y_onehot),name=\"cross_entropy_loss\")\n",
        "  \n",
        "  ##Optimizer\n",
        "  optimizer=tf.train.AdamOptimizer(learning_rate)\n",
        "  optimizer=optimizer.minimize(cross_entropy_loss,name=\"train_op\")\n",
        "  \n",
        "  #Computing prediction Accuracy\n",
        "  correct_prediction=tf.equal(prediction['labels'],tf_y,name=\"correct_preds\")\n",
        "  accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name=\"accuracy\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyrvSPWyb6nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save(saver,sess,epoch,path=\"./model/\"):\n",
        "  if not os.path.isdir(path):\n",
        "    os.makedirs(path)\n",
        "  print(\"Saver Model in %s\" %path)\n",
        "  saver.save(sess,os.path.join(path,\"cnn-model.ckpt\"),global_step=epoch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKExW7WNjOCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load(saver,sess,path,epoch):\n",
        "  print(\"Loading model from %s\" %path)\n",
        "  saver.restore(sess,os.path.join(path,\"cnn-model.ckpt-%d\"%epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEGyd2nqjo9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(sess,training_set,validation_set=None,\n",
        "         initialization=True,epochs=20,shuffle=True,\n",
        "         dropout=0.5,random_seed=None):\n",
        "  \n",
        "  X_data=np.array(training_set[0])\n",
        "  y_data=np.array(training_set[1])\n",
        "  training_loss=[]\n",
        "  \n",
        "  #initializing variables\n",
        "  if initialize:\n",
        "    sess.run(tf.global_variables_initializer)\n",
        "  \n",
        "  np.random.seed(random_seed)\n",
        "  \n",
        "  for epoch in range(1,epoch+1):\n",
        "    batch_gen=batch_generator(X_data,y_data,shuffle=shuffle)\n",
        "    avg_loss=0.0\n",
        "    for i,(batch_x,batch_y) in enumerate(batch_gen):\n",
        "      feed={\"tf_x:0\":batch_x,\n",
        "           \"tf_y:0\":batch_y,\n",
        "           \"fc_keep_prob:0\":dropout}\n",
        "      loss,_=sess.run([\"cross_entropy_loss:0\",\"train_op\"],feed_dict=feed)\n",
        "      avg_loss+=loss\n",
        "    training_loss.append(avg_loss/(i+1))\n",
        "    print(\" Epoch %02d Training Average Loss : %7.3f\"%(epoch,avg_loss),end=\" \")\n",
        "    if validation_set is not None:\n",
        "      feed={\"tf_x:0\":validation_set[0],\n",
        "           \"tf_y:0\":validation_set[1],\n",
        "           \"fc_keep_prob:0\":1.0}\n",
        "      valid_acc=sess.run(\"Accuracy : 0\",feed_dict=feed)\n",
        "      print(\" Validation Accuracy : %7.3f\" %valid_acc)\n",
        "    else:\n",
        "      print()\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah3eIDJTmizp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(sess,X_test,return_prob=False):\n",
        "  feed={\"tf_x:0\":X_test,\n",
        "       \"fc_keep_prob:0\":1.0}\n",
        "  if return_prob:\n",
        "    return sess.run(\"probabilities:0\",feed_dict=feed)\n",
        "  else:\n",
        "    return sess.run(\"labels:0\",feed_dict=feed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_4yyQMnK2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}