{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C15_CNN_Mnist_Tf_Layer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyam-Khokhariya/ML-Python/blob/master/C15_CNN_Mnist_Tf_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MokDDmEVlRFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfnbFLrknjU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist=np.load(\"mnist_scaled.npz\")\n",
        "X_train,y_train,X_test,y_test=[mnist[f] for f in mnist.files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkwCZIZjVisu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c9b90d82-6044-47ae-ffca-d25ac2b98dd1"
      },
      "source": [
        "X_valid,y_valid=X_train[50000:,:],y_train[50000:]\n",
        "X_train,y_train=X_train[:50000,:],y_train[:50000]\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_valid.shape,y_valid.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784) (50000,)\n",
            "(10000, 784) (10000,)\n",
            "(10000, 784) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr7vCXHwVjE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(X,y,batch_size=64,shuffle=False,random_seed=None):\n",
        "  idx=np.arange(y.shape[0])\n",
        "  if shuffle:\n",
        "    rng=np.random.RandomState(random_seed)\n",
        "    rng.shuffle(idx)\n",
        "    X=X[idx]\n",
        "    y=y[idx]\n",
        "  for i in range(0,X.shape[0],batch_size):\n",
        "    yield (X[i:i+batch_size,:],y[i:i+batch_size])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8DuwwtPVjLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_val=np.mean(X_train,axis=0)\n",
        "std_val=np.std(X_train)\n",
        "\n",
        "X_train_centered=(X_train-mean_val)/std_val\n",
        "X_valid_centered=(X_valid-mean_val)/std_val\n",
        "X_test_centered=(X_test-mean_val)/std_val\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypE2hWlaVjSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNN(object):\n",
        "    def __init__(self,batchsize=64,epochs=20,\n",
        "                 learning_rate=1e-4,dropout_rate=0.5,\n",
        "                 shuffle=True,random_seed=None):\n",
        "        np.random.seed(random_seed)\n",
        "        self.batchsize=batchsize\n",
        "        self.epochs=epochs\n",
        "        self.learning_rate=learning_rate\n",
        "        self.dropout_rate=dropout_rate\n",
        "        self.shuffle=shuffle\n",
        "\n",
        "        g=tf.Graph()\n",
        "        with g.as_default():\n",
        "            #Set random Seed\n",
        "            tf.set_random_seed(random_seed)\n",
        "\n",
        "            #Building CNN\n",
        "            self.build()\n",
        "\n",
        "            #Initializer\n",
        "            self.init_op=tf.global_variables_initializer()\n",
        "\n",
        "            #Saver\n",
        "            self.saver=tf.train.Saver()\n",
        "\n",
        "        #Creating Session\n",
        "        self.sess=tf.Session(graph=g)\n",
        "\n",
        "    def build(self):\n",
        "        #Placeholder For X & y\n",
        "        tf_x=tf.placeholder(tf.float32,shape=[None,784],name=\"tf_x\")\n",
        "        tf_y=tf.placeholder(tf.int32,shape=[None],name=\"tf_y\")\n",
        "        is_train=tf.placeholder(tf.bool,shape=(),name=\"is_train\")\n",
        "\n",
        "        #reshaping x to 4D tensor\n",
        "        tf_x_image=tf.reshape(tf_x,shape=[-1,28,28,1],name=\"input_x_2dimages\")\n",
        "\n",
        "        #One-Hot Encoding\n",
        "        tf_y_onehot=tf.one_hot(indices=tf_y,depth=10,dtype=tf.float32,name=\"input_y_onehot\")\n",
        "\n",
        "        #1st Layer Conv_1\n",
        "        h1=tf.layers.conv2d(tf_x_image,filters=32,kernel_size=(5,5),activation=tf.nn.relu)\n",
        "\n",
        "        ##Max Pooling\n",
        "        h1_pool=tf.layers.max_pooling2d(h1,pool_size=(2,2),strides=(2,2))\n",
        "\n",
        "        #2nd Layer Conv_2\n",
        "        h2=tf.layers.conv2d(h1_pool,filters=64,kernel_size=(5,5),activation=tf.nn.relu)\n",
        "\n",
        "        #Max Pooling\n",
        "        h2_pool=tf.layers.max_pooling2d(h2,pool_size=(2,2),strides=(2,2))\n",
        "\n",
        "        #3rd Layer Fully Connected\n",
        "        input_shape=h2_pool.get_shape().as_list()\n",
        "        n_input_units=np.prod(input_shape[1:])\n",
        "        h2_pool_flat=tf.reshape(h2_pool,shape=[-1,n_input_units])\n",
        "        h3=tf.layers.dense(h2_pool_flat,1024,activation=tf.nn.relu)\n",
        "\n",
        "        #Dropout\n",
        "        h3_drop=tf.layers.dropout(h3,rate=self.dropout_rate,training=is_train)\n",
        "\n",
        "        #4th Layer Fully Connected (Linear Activation)\n",
        "        h4=tf.layers.dense(h3_drop,10,activation=None)\n",
        "\n",
        "        ##Prediction\n",
        "        prediction={\"probabilities\":tf.nn.softmax(h4,name=\"probabilities\"),\n",
        "                    \"labels\":tf.cast(tf.argmax(h4,axis=1),tf.int32,name=\"labels\")}\n",
        "\n",
        "        #Loss function & Optimization\n",
        "        cross_entropy_loss=tf.reduce_mean(\n",
        "            tf.nn.softmax_cross_entropy_with_logits(logits=h4,labels=tf_y_onehot),\n",
        "            name=\"cross_entropy_loss\")\n",
        "\n",
        "        #Optimizer\n",
        "        optimizer=tf.train.AdamOptimizer(self.learning_rate)\n",
        "        optimizer=optimizer.minimize(cross_entropy_loss,name=\"train_op\")\n",
        "\n",
        "        #Finding Accuracy\n",
        "        correct_predictions=tf.equal(prediction['labels'],tf_y,name=\"correct_pred\")\n",
        "        accuracy=tf.reduce_mean(tf.cast(correct_predictions,tf.float32),name=\"accuracy\")\n",
        "\n",
        "    def save(self,epoch,path=\"./tflayers-model/\"):\n",
        "        if not os.path.isdir(path):\n",
        "            os.makedirs(path)\n",
        "        print(\"Saving model at %s\"%path)\n",
        "        self.saver.save(self.sess,os.path.join(path,\"model.ckpt\"),global_step=epoch)\n",
        "\n",
        "    def load(self,epoch,path):\n",
        "        print(\"Loading from %s\"%path)\n",
        "        self.saver.restore(self.sess,os.path.join(path,\"model.ckpt-%d\")%epoch)\n",
        "\n",
        "    def train(self,training_set,validation_set=None,initialize=True):\n",
        "        #initialize variables\n",
        "        if initialize:\n",
        "            self.sess.run(self.init_op)\n",
        "        self.train_cost=[]\n",
        "        X_data=np.array(training_set[0])\n",
        "        y_data=np.array(training_set[1])\n",
        "\n",
        "        for epoch in range(1,self.epochs+1):\n",
        "            batch_gen=batch_generator(X_data,y_data,shuffle=self.shuffle)\n",
        "\n",
        "            avg_loss=0.0\n",
        "            for i,(batch_x,batch_y) in enumerate(batch_gen):\n",
        "                feed={\"tf_x:0\":batch_x,\n",
        "                      \"tf_y:0\":batch_y,\n",
        "                      \"is_train:0\":True} #for Dropout\n",
        "                loss,_=self.sess.run([\"cross_entropy_loss:0\",\"train_op\"],feed_dict=feed)\n",
        "                avg_loss+=loss\n",
        "\n",
        "            print(\"Epoch %02d: Training Average Loss : %7.3f\"%(epoch,avg_loss),end=\" \")\n",
        "\n",
        "            if validation_set is not None:\n",
        "                feed={\"tf_x:0\":validation_set[0],\n",
        "                      \"tf_y:0\":validation_set[1],\n",
        "                      \"is_train:0\":False}\n",
        "                valid_acc=self.sess.run(\"accuracy:0\",feed_dict=feed)\n",
        "                print(\"Validation Accuracy : %7.3f\"%valid_acc)\n",
        "            else:\n",
        "                print()\n",
        "\n",
        "    def predict(self,X_test,return_prob=False):\n",
        "        feed={\"tf_x:0\":X_test,\n",
        "              \"is_train:0\":False}\n",
        "        if return_prob:\n",
        "            return self.sess.run(\"probabilities:0\",feed_dict=feed)\n",
        "        else:\n",
        "            return self.sess.run(\"labels:0\",feed_dict=feed)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pskhd1npVjZ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "643de7d7-689c-4eb4-e823-29c5814977cf"
      },
      "source": [
        "cnn=ConvNN(random_seed=123)\n",
        "cnn.train(training_set=(X_train_centered,y_train),validation_set=(X_valid_centered,y_valid),\n",
        "          initialize=True)\n",
        "cnn.save(epoch=20)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 01: Training Average Loss : 261.666 Validation Accuracy :   0.975\n",
            "Epoch 02: Training Average Loss :  72.429 Validation Accuracy :   0.983\n",
            "Epoch 03: Training Average Loss :  49.559 Validation Accuracy :   0.986\n",
            "Epoch 04: Training Average Loss :  38.993 Validation Accuracy :   0.988\n",
            "Epoch 05: Training Average Loss :  31.129 Validation Accuracy :   0.989\n",
            "Epoch 06: Training Average Loss :  26.671 Validation Accuracy :   0.989\n",
            "Epoch 07: Training Average Loss :  22.400 Validation Accuracy :   0.990\n",
            "Epoch 08: Training Average Loss :  19.730 Validation Accuracy :   0.991\n",
            "Epoch 09: Training Average Loss :  17.438 Validation Accuracy :   0.991\n",
            "Epoch 10: Training Average Loss :  15.663 Validation Accuracy :   0.991\n",
            "Epoch 11: Training Average Loss :  12.779 Validation Accuracy :   0.991\n",
            "Epoch 12: Training Average Loss :  11.211 Validation Accuracy :   0.992\n",
            "Epoch 13: Training Average Loss :   9.554 Validation Accuracy :   0.992\n",
            "Epoch 14: Training Average Loss :   8.913 Validation Accuracy :   0.992\n",
            "Epoch 15: Training Average Loss :   7.755 Validation Accuracy :   0.992\n",
            "Epoch 16: Training Average Loss :   7.089 Validation Accuracy :   0.992\n",
            "Epoch 17: Training Average Loss :   6.186 Validation Accuracy :   0.992\n",
            "Epoch 18: Training Average Loss :   5.269 Validation Accuracy :   0.993\n",
            "Epoch 19: Training Average Loss :   4.624 Validation Accuracy :   0.992\n",
            "Epoch 20: Training Average Loss :   4.863 Validation Accuracy :   0.992\n",
            "Saving model at ./tflayers-model/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVjTy4HAV0zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "523cf587-03cc-4357-aa81-6b1d2a55cb8e"
      },
      "source": [
        "cnn2=ConvNN(random_seed=123)\n",
        "cnn2.load(epoch=20,path=\"./tflayers-model/\")\n",
        "print(cnn2.predict(X_test_centered[:10,:]))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from ./tflayers-model/\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./tflayers-model/model.ckpt-20\n",
            "[7 2 1 0 4 1 4 9 5 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1PJe1Y5V1A7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd46db23-e8df-432a-9cbb-8a4d62e13043"
      },
      "source": [
        "pred=cnn2.predict(X_test_centered)\n",
        "print(\"Test Accuracy : %.2f\"%(100 * np.sum(y_test==pred)/len(y_test)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy : 99.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQA-FBnoV1K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}