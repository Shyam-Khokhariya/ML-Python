{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C16_Movie_Review_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyam-Khokhariya/ML-Python/blob/master/C16_Movie_Review_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9Gl8geaFZi",
        "colab_type": "code",
        "outputId": "d3e33034-f8c3-44cf-d5f3-aa05cdf109ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip3 install pyprind\n",
        "import pyprind\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from string import punctuation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.6/dist-packages (2.11.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYsjQO-ZakFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"movie_data.csv\",encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zP2CTcXvDAl",
        "colab_type": "code",
        "outputId": "2eaa4325-664f-44d9-a076-5d429ba8cad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "review=\"Hello, everyone . My Self ! @ shyam ?\"\n",
        "text=\"\"\n",
        "for c in review:\n",
        "  if c not in punctuation:\n",
        "    text=text+c\n",
        "  else:\n",
        "    text=text+\" \"\n",
        "print(text)\n",
        "text=\" \".join(text.split()).lower()\n",
        "print(text)\n",
        "\n",
        "sequence_length=200\n",
        "sequences=np.zeros(sequence_length,dtype=str)\n",
        "r_arr=np.array(text)\n",
        "sequences[-len(text):]=text[-sequence_length:]\n",
        "print(sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello  everyone   My Self     shyam  \n",
            "hello everyone my self shyam\n",
            "['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h'\n",
            " 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep9OCB5lke7V",
        "colab_type": "code",
        "outputId": "ba36a86d-fc32-4d12-b9c5-1f662fdac291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from collections import Counter\n",
        "counts = Counter()\n",
        "pbar = pyprind.ProgBar(len(df['review']),title='Counting words occurrences')\n",
        "for i,review in enumerate(df['review']):\n",
        "  #text = ''.join([c if c not in punctuation else ' '+c+' ' for c in review]).lower()\n",
        "  text=\"\"\n",
        "  for c in review:\n",
        "    if c not in punctuation:\n",
        "      text=text+c\n",
        "    else:\n",
        "      text=text+\" \"\n",
        "  text=\" \".join(text.split()).lower()\n",
        "  df.loc[i,'review'] = text\n",
        "  pbar.update()\n",
        "  counts.update(text.split())\n",
        " ## Create a mapping\n",
        " ## Map each unique word to an integer\n",
        "word_counts = sorted(counts, key=counts.get, reverse=True)\n",
        "print(word_counts[:5])\n",
        "word_to_int = {word: ii for ii, word in  enumerate(word_counts, 1)}\n",
        "mapped_reviews = []\n",
        "pbar = pyprind.ProgBar(len(df['review']),  title='Map reviews to ints')\n",
        "for review in df['review']:\n",
        "  mapped_reviews.append([word_to_int[word] for word in review.split()])\n",
        "  pbar.update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting words occurrences\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:06:26\n",
            "Map reviews to ints\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['the', 'and', 'a', 'of', 'to']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:03\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldLRLD8wulu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining same length sequences\n",
        "\n",
        "sequence_length=200\n",
        "sequences=np.zeros((len(mapped_reviews),sequence_length),dtype=int)\n",
        "for i,row in enumerate(mapped_reviews):\n",
        "  review_arr=np.array(row)\n",
        "  sequences[i,-len(row):]=review_arr[-sequence_length:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVH8ibeCy15U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=sequences[:25000,:]\n",
        "y_train=df.loc[:25000,\"sentiment\"].values\n",
        "X_test=sequences[25000:,:]\n",
        "y_test=df.loc[25000:,\"sentiment\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Fz3KVSzSnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123)\n",
        "\n",
        "#Function for mini-batch\n",
        "def create_batch_generator(x,y=None,batch_size=64):\n",
        "  n_batches=len(x)//batch_size\n",
        "  x=x[:n_batches*batch_size]\n",
        "  if y is not None:\n",
        "    y=y[:n_batches*batch_size]\n",
        "  for ii in range(0,len(x),batch_size):\n",
        "    if y is not None:\n",
        "      yield x[ii:ii+batch_size],y[ii:ii+batch_size]\n",
        "    else:\n",
        "      yield x[ii:ii+batch_size]\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_FMUNRK0fxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SentimentRNN(object):\n",
        "    def __init__(self,n_words,seq_len=200,\n",
        "                 lstm_size=256,num_layers=1,batch_size=64,\n",
        "                 learning_rate=0.0001,embed_size=200):\n",
        "        self.n_words=n_words\n",
        "        self.seq_len=seq_len\n",
        "        self.lstm_size=lstm_size            #number of hidden units\n",
        "        self.num_layers=num_layers\n",
        "        self.batch_size=batch_size\n",
        "        self.learning_rate=learning_rate\n",
        "        self.embed_size=embed_size\n",
        "\n",
        "        self.g= tf.Graph()\n",
        "        with self.g.as_default():\n",
        "            tf.set_random_seed(123)\n",
        "            self.build()\n",
        "            self.saver=tf.train.Saver()\n",
        "            self.init_op=tf.global_variables_initializer()\n",
        "\n",
        "    def build(self):\n",
        "\n",
        "        #defining placeholder\n",
        "        tf_x=tf.placeholder(tf.int32,shape=(self.batch_size,self.seq_len),name=\"tf_x\")\n",
        "        tf_y=tf.placeholder(tf.float32,shape=(self.batch_size),name=\"tf_y\")\n",
        "        tf_keepprob=tf.placeholder(tf.float32,name=\"tf_keepprob\")\n",
        "\n",
        "        #creating embeded layer\n",
        "        embedding=tf.Variable(tf.random_uniform((self.n_words,self.embed_size),minval=-1,maxval=1),name=\"embedding\")\n",
        "        embed_x=tf.nn.embedding_lookup(embedding,tf_x,name=\"embeded_x\")\n",
        "\n",
        "        #Define LSTM cell and stack them together\n",
        "        cells=tf.contrib.rnn.MultiRNNCell(\n",
        "            [tf.contrib.rnn.DropoutWrapper(\n",
        "                tf.contrib.rnn.BasicLSTMCell(self.lstm_size),output_keep_prob=tf_keepprob)\n",
        "                for i in range(self.num_layers)\n",
        "            ])\n",
        "        ##Define Initial State\n",
        "        self.initial_state=cells.zero_state(self.batch_size,tf.float32)\n",
        "        print(\" << initial state >> \",self.initial_state)\n",
        "\n",
        "        lstm_output,self.final_state=tf.nn.dynamic_rnn(cells,embed_x,initial_state=self.initial_state)\n",
        "\n",
        "        #   NOTE: LSTM Output Shape:\n",
        "        #   [batch_size,max time,cells.output_size]\n",
        "        print(\" << lstm_output >> \",lstm_output)\n",
        "        print(\" << final state >> \",self.final_state)\n",
        "\n",
        "        logits=tf.layers.dense(inputs=lstm_output[:,-1],\n",
        "                               units=1,activation=None,name=\"logits\")\n",
        "        logits=tf.squeeze(logits,name=\"logits_squeezed\")\n",
        "\n",
        "        print(\" << logits >> \",logits)\n",
        "        y_proba=tf.nn.sigmoid(logits,name=\"probabilities\")\n",
        "\n",
        "        predictions={\n",
        "            \"probabilities\":y_proba,\n",
        "            \"labels\":tf.cast(tf.round(y_proba),tf.int32,name=\"labels\")\n",
        "        }\n",
        "        print(\" << predictions >> \",predictions)\n",
        "\n",
        "        #Define cost Function\n",
        "        cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_y,logits=logits),name=\"cost\")\n",
        "\n",
        "        #Define Optimizer\n",
        "        optimizer=tf.train.AdamOptimizer(self.learning_rate)\n",
        "        train_op=optimizer.minimize(cost,name=\"train_op\")\n",
        "\n",
        "    def train(self,X_train,y_train,num_epochs):\n",
        "        with tf.Session(graph=self.g) as sess:\n",
        "            sess.run(self.init_op)\n",
        "            iteration=1\n",
        "            for epochs in range(num_epochs):\n",
        "                state=sess.run(self.initial_state)\n",
        "\n",
        "                for batch_x,batch_y in create_batch_generator(X_train,y_train,self.batch_size):\n",
        "                    feed={\"tf_x:0\":batch_x,\n",
        "                          \"tf_y:0\":batch_y,\n",
        "                          \"tf_keepprob:0\":0.5,\n",
        "                          self.initial_state:state}\n",
        "                    loss,_,state=sess.run([\"cost:0\",\"train_op\",self.final_state],feed_dict=feed)\n",
        "\n",
        "                    if iteration%20==0:\n",
        "                        print(\"Epoch : %d/%d Iteration : %d  | Train Loss : %7.5f\"%(epochs+1,num_epochs,iteration,loss))\n",
        "\n",
        "                    iteration+=1\n",
        "                if(epochs%10==0):\n",
        "                    self.saver.save(sess,\"model/sentiment-%d.ckpt\"%epochs)\n",
        "\n",
        "    def predict(self,X_data,return_prob=False):\n",
        "        preds=[]\n",
        "        with tf.Session(graph=self.g) as sess:\n",
        "            self.saver.restore(sess,tf.train.latest_checkpoint(\"./model/\"))\n",
        "            test_state=sess.run(self.initial_state)\n",
        "            for ii,batch_x in enumerate(create_batch_generator(X_data,None,batch_size=self.batch_size),1):\n",
        "                feed={\"tf_x:0\":batch_x,\n",
        "                      \"tf_keepprob:0\":1.0,\n",
        "                      self.initial_state:test_state}\n",
        "                if return_prob:\n",
        "                    pred,test_state=sess.run([\"probabilities:0\",self.final_state],feed_dict=feed)\n",
        "                else:\n",
        "                    pred,test_state=sess.run([\"labels:0\",self.final_state],feed_dict=feed)\n",
        "                preds.append(pred)\n",
        "\n",
        "        return np.concatenate(preds)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIzw6W7vfdvI",
        "colab_type": "code",
        "outputId": "c053e8a3-c985-4e30-950d-2e39979c765c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "n_words=max(list(word_to_int.values()))+1\n",
        "rnn=SentimentRNN(n_words=n_words,\n",
        "                seq_len=sequence_length,\n",
        "                embed_size=256,\n",
        "                lstm_size=128,\n",
        "                num_layers=1,\n",
        "                batch_size=100,\n",
        "                learning_rate=0.001)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " << initial state >>  (LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(100, 128) dtype=float32>),)\n",
            " << lstm_output >>  Tensor(\"rnn/transpose_1:0\", shape=(100, 200, 128), dtype=float32)\n",
            " << final state >>  (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(100, 128) dtype=float32>),)\n",
            " << logits >>  Tensor(\"logits_squeezed:0\", shape=(100,), dtype=float32)\n",
            " << predictions >>  {'probabilities': <tf.Tensor 'probabilities:0' shape=(100,) dtype=float32>, 'labels': <tf.Tensor 'labels:0' shape=(100,) dtype=int32>}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QipWie2ggg_X",
        "colab_type": "code",
        "outputId": "a60a5289-1828-49ed-be24-471f4a0fbd26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2142
        }
      },
      "source": [
        "rnn.train(X_train,y_train,num_epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1/10 Iteration : 20  | Train Loss : 0.00024\n",
            "Epoch : 1/10 Iteration : 40  | Train Loss : 0.00009\n",
            "Epoch : 1/10 Iteration : 60  | Train Loss : 0.00006\n",
            "Epoch : 1/10 Iteration : 80  | Train Loss : 0.00005\n",
            "Epoch : 1/10 Iteration : 100  | Train Loss : 0.00004\n",
            "Epoch : 1/10 Iteration : 120  | Train Loss : 0.00003\n",
            "Epoch : 1/10 Iteration : 140  | Train Loss : 1.71319\n",
            "Epoch : 1/10 Iteration : 160  | Train Loss : 0.03230\n",
            "Epoch : 1/10 Iteration : 180  | Train Loss : 0.01159\n",
            "Epoch : 1/10 Iteration : 200  | Train Loss : 0.01352\n",
            "Epoch : 1/10 Iteration : 220  | Train Loss : 0.01306\n",
            "Epoch : 1/10 Iteration : 240  | Train Loss : 0.01417\n",
            "Epoch : 2/10 Iteration : 260  | Train Loss : 3.49436\n",
            "Epoch : 2/10 Iteration : 280  | Train Loss : 0.99158\n",
            "Epoch : 2/10 Iteration : 300  | Train Loss : 0.34082\n",
            "Epoch : 2/10 Iteration : 320  | Train Loss : 0.14943\n",
            "Epoch : 2/10 Iteration : 340  | Train Loss : 0.08856\n",
            "Epoch : 2/10 Iteration : 360  | Train Loss : 0.06205\n",
            "Epoch : 2/10 Iteration : 380  | Train Loss : 2.97360\n",
            "Epoch : 2/10 Iteration : 400  | Train Loss : 1.11406\n",
            "Epoch : 2/10 Iteration : 420  | Train Loss : 0.51988\n",
            "Epoch : 2/10 Iteration : 440  | Train Loss : 0.29651\n",
            "Epoch : 2/10 Iteration : 460  | Train Loss : 0.21706\n",
            "Epoch : 2/10 Iteration : 480  | Train Loss : 0.14156\n",
            "Epoch : 2/10 Iteration : 500  | Train Loss : 0.11243\n",
            "Epoch : 3/10 Iteration : 520  | Train Loss : 1.44866\n",
            "Epoch : 3/10 Iteration : 540  | Train Loss : 0.76916\n",
            "Epoch : 3/10 Iteration : 560  | Train Loss : 0.44411\n",
            "Epoch : 3/10 Iteration : 580  | Train Loss : 0.28569\n",
            "Epoch : 3/10 Iteration : 600  | Train Loss : 0.19211\n",
            "Epoch : 3/10 Iteration : 620  | Train Loss : 0.14752\n",
            "Epoch : 3/10 Iteration : 640  | Train Loss : 1.49378\n",
            "Epoch : 3/10 Iteration : 660  | Train Loss : 0.84715\n",
            "Epoch : 3/10 Iteration : 680  | Train Loss : 0.55321\n",
            "Epoch : 3/10 Iteration : 700  | Train Loss : 0.38963\n",
            "Epoch : 3/10 Iteration : 720  | Train Loss : 0.27504\n",
            "Epoch : 3/10 Iteration : 740  | Train Loss : 0.19422\n",
            "Epoch : 4/10 Iteration : 760  | Train Loss : 1.61715\n",
            "Epoch : 4/10 Iteration : 780  | Train Loss : 0.94780\n",
            "Epoch : 4/10 Iteration : 800  | Train Loss : 0.62582\n",
            "Epoch : 4/10 Iteration : 820  | Train Loss : 0.41057\n",
            "Epoch : 4/10 Iteration : 840  | Train Loss : 0.27603\n",
            "Epoch : 4/10 Iteration : 860  | Train Loss : 0.16008\n",
            "Epoch : 4/10 Iteration : 880  | Train Loss : 1.73304\n",
            "Epoch : 4/10 Iteration : 900  | Train Loss : 0.94765\n",
            "Epoch : 4/10 Iteration : 920  | Train Loss : 0.55398\n",
            "Epoch : 4/10 Iteration : 940  | Train Loss : 0.25013\n",
            "Epoch : 4/10 Iteration : 960  | Train Loss : 0.09337\n",
            "Epoch : 4/10 Iteration : 980  | Train Loss : 0.00964\n",
            "Epoch : 4/10 Iteration : 1000  | Train Loss : 0.00275\n",
            "Epoch : 5/10 Iteration : 1020  | Train Loss : 0.10715\n",
            "Epoch : 5/10 Iteration : 1040  | Train Loss : 0.02367\n",
            "Epoch : 5/10 Iteration : 1060  | Train Loss : 0.01308\n",
            "Epoch : 5/10 Iteration : 1080  | Train Loss : 0.00834\n",
            "Epoch : 5/10 Iteration : 1100  | Train Loss : 0.00640\n",
            "Epoch : 5/10 Iteration : 1120  | Train Loss : 0.00625\n",
            "Epoch : 5/10 Iteration : 1140  | Train Loss : 0.78444\n",
            "Epoch : 5/10 Iteration : 1160  | Train Loss : 0.04073\n",
            "Epoch : 5/10 Iteration : 1180  | Train Loss : 0.01873\n",
            "Epoch : 5/10 Iteration : 1200  | Train Loss : 0.01422\n",
            "Epoch : 5/10 Iteration : 1220  | Train Loss : 0.01107\n",
            "Epoch : 5/10 Iteration : 1240  | Train Loss : 0.01127\n",
            "Epoch : 6/10 Iteration : 1260  | Train Loss : 3.06751\n",
            "Epoch : 6/10 Iteration : 1280  | Train Loss : 0.37429\n",
            "Epoch : 6/10 Iteration : 1300  | Train Loss : 0.16892\n",
            "Epoch : 6/10 Iteration : 1320  | Train Loss : 0.10140\n",
            "Epoch : 6/10 Iteration : 1340  | Train Loss : 0.06721\n",
            "Epoch : 6/10 Iteration : 1360  | Train Loss : 0.04954\n",
            "Epoch : 6/10 Iteration : 1380  | Train Loss : 2.96478\n",
            "Epoch : 6/10 Iteration : 1400  | Train Loss : 1.11229\n",
            "Epoch : 6/10 Iteration : 1420  | Train Loss : 0.51470\n",
            "Epoch : 6/10 Iteration : 1440  | Train Loss : 0.27405\n",
            "Epoch : 6/10 Iteration : 1460  | Train Loss : 0.18544\n",
            "Epoch : 6/10 Iteration : 1480  | Train Loss : 0.13045\n",
            "Epoch : 6/10 Iteration : 1500  | Train Loss : 0.09188\n",
            "Epoch : 7/10 Iteration : 1520  | Train Loss : 1.19809\n",
            "Epoch : 7/10 Iteration : 1540  | Train Loss : 0.63856\n",
            "Epoch : 7/10 Iteration : 1560  | Train Loss : 0.37438\n",
            "Epoch : 7/10 Iteration : 1580  | Train Loss : 0.31656\n",
            "Epoch : 7/10 Iteration : 1600  | Train Loss : 0.22285\n",
            "Epoch : 7/10 Iteration : 1620  | Train Loss : 0.17260\n",
            "Epoch : 7/10 Iteration : 1640  | Train Loss : 1.19626\n",
            "Epoch : 7/10 Iteration : 1660  | Train Loss : 0.67611\n",
            "Epoch : 7/10 Iteration : 1680  | Train Loss : 0.52246\n",
            "Epoch : 7/10 Iteration : 1700  | Train Loss : 0.34623\n",
            "Epoch : 7/10 Iteration : 1720  | Train Loss : 0.23001\n",
            "Epoch : 7/10 Iteration : 1740  | Train Loss : 0.14432\n",
            "Epoch : 8/10 Iteration : 1760  | Train Loss : 1.34158\n",
            "Epoch : 8/10 Iteration : 1780  | Train Loss : 0.72100\n",
            "Epoch : 8/10 Iteration : 1800  | Train Loss : 0.56309\n",
            "Epoch : 8/10 Iteration : 1820  | Train Loss : 0.44969\n",
            "Epoch : 8/10 Iteration : 1840  | Train Loss : 0.32538\n",
            "Epoch : 8/10 Iteration : 1860  | Train Loss : 0.23282\n",
            "Epoch : 8/10 Iteration : 1880  | Train Loss : 1.07286\n",
            "Epoch : 8/10 Iteration : 1900  | Train Loss : 0.77588\n",
            "Epoch : 8/10 Iteration : 1920  | Train Loss : 0.63278\n",
            "Epoch : 8/10 Iteration : 1940  | Train Loss : 0.41863\n",
            "Epoch : 8/10 Iteration : 1960  | Train Loss : 0.31173\n",
            "Epoch : 8/10 Iteration : 1980  | Train Loss : 0.29260\n",
            "Epoch : 8/10 Iteration : 2000  | Train Loss : 0.23342\n",
            "Epoch : 9/10 Iteration : 2020  | Train Loss : 0.86581\n",
            "Epoch : 9/10 Iteration : 2040  | Train Loss : 0.54087\n",
            "Epoch : 9/10 Iteration : 2060  | Train Loss : 0.35863\n",
            "Epoch : 9/10 Iteration : 2080  | Train Loss : 0.36435\n",
            "Epoch : 9/10 Iteration : 2100  | Train Loss : 0.26939\n",
            "Epoch : 9/10 Iteration : 2120  | Train Loss : 0.22954\n",
            "Epoch : 9/10 Iteration : 2140  | Train Loss : 0.80318\n",
            "Epoch : 9/10 Iteration : 2160  | Train Loss : 0.57067\n",
            "Epoch : 9/10 Iteration : 2180  | Train Loss : 0.52629\n",
            "Epoch : 9/10 Iteration : 2200  | Train Loss : 0.36608\n",
            "Epoch : 9/10 Iteration : 2220  | Train Loss : 0.24894\n",
            "Epoch : 9/10 Iteration : 2240  | Train Loss : 0.19913\n",
            "Epoch : 10/10 Iteration : 2260  | Train Loss : 0.96075\n",
            "Epoch : 10/10 Iteration : 2280  | Train Loss : 0.61603\n",
            "Epoch : 10/10 Iteration : 2300  | Train Loss : 0.51295\n",
            "Epoch : 10/10 Iteration : 2320  | Train Loss : 0.41335\n",
            "Epoch : 10/10 Iteration : 2340  | Train Loss : 0.27752\n",
            "Epoch : 10/10 Iteration : 2360  | Train Loss : 0.21142\n",
            "Epoch : 10/10 Iteration : 2380  | Train Loss : 0.92370\n",
            "Epoch : 10/10 Iteration : 2400  | Train Loss : 0.62319\n",
            "Epoch : 10/10 Iteration : 2420  | Train Loss : 0.49416\n",
            "Epoch : 10/10 Iteration : 2440  | Train Loss : 0.35465\n",
            "Epoch : 10/10 Iteration : 2460  | Train Loss : 0.25901\n",
            "Epoch : 10/10 Iteration : 2480  | Train Loss : 0.25579\n",
            "Epoch : 10/10 Iteration : 2500  | Train Loss : 0.13624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG30S2C0hmrr",
        "colab_type": "code",
        "outputId": "532d1a3e-87c0-4723-9567-f5cf09b74e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pred=rnn.predict(X_test)\n",
        "y_true=y_test[:len(pred)]\n",
        "print(\"Test Accuracy : %.3f\"%(np.sum(y_true==pred)/len(y_true)))\n",
        "\n",
        "prob=rnn.predict(X_test,return_prob=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./model/sentiment-0.ckpt\n",
            "Test Accuracy : 0.500\n",
            "INFO:tensorflow:Restoring parameters from ./model/sentiment-0.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m45JiEmBtEf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}