{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C16_Movie_Review_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shyam-Khokhariya/ML-Python/blob/master/C16_Movie_Review_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9Gl8geaFZi",
        "colab_type": "code",
        "outputId": "ceb7de8c-9bec-4a55-d4ef-6da118fe77fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip3 install pyprind\n",
        "import pyprind\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from string import punctuation"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyprind\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/30/e76fb0c45da8aef49ea8d2a90d4e7a6877b45894c25f12fb961f009a891e/PyPrind-2.11.2-py3-none-any.whl\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYsjQO-ZakFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"movie_data.csv\",encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zP2CTcXvDAl",
        "colab_type": "code",
        "outputId": "6858bf6b-b6ea-452a-ecdf-180468ad45fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "review=\"Hello, everyone . My Self ! @ shyam ?\"\n",
        "text=\"\"\n",
        "for c in review:\n",
        "  if c not in punctuation:\n",
        "    text=text+c\n",
        "  else:\n",
        "    text=text+\" \"\n",
        "print(text)\n",
        "text=\" \".join(text.split()).lower()\n",
        "print(text)\n",
        "\n",
        "sequence_length=200\n",
        "sequences=np.zeros(sequence_length,dtype=str)\n",
        "r_arr=np.array(text)\n",
        "sequences[-len(text):]=text[-sequence_length:]\n",
        "print(sequences)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello  everyone   My Self     shyam  \n",
            "hello everyone my self shyam\n",
            "['' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' '' ''\n",
            " '' '' '' '' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h'\n",
            " 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h' 'h']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep9OCB5lke7V",
        "colab_type": "code",
        "outputId": "33900b15-93f1-4bbb-9541-ab2d549fdc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from collections import Counter\n",
        "counts = Counter()\n",
        "pbar = pyprind.ProgBar(len(df['review']),title='Counting words occurrences')\n",
        "for i,review in enumerate(df['review']):\n",
        "  #text = ''.join([c if c not in punctuation else ' '+c+' ' for c in review]).lower()\n",
        "  text=\"\"\n",
        "  for c in review:\n",
        "    if c not in punctuation:\n",
        "      text=text+c\n",
        "    else:\n",
        "      text=text+\" \"\n",
        "  text=\" \".join(text.split()).lower()\n",
        "  df.loc[i,'review'] = text\n",
        "  pbar.update()\n",
        "  counts.update(text.split())\n",
        " ## Create a mapping\n",
        " ## Map each unique word to an integer\n",
        "word_counts = sorted(counts, key=counts.get, reverse=True)\n",
        "print(word_counts[:5])\n",
        "word_to_int = {word: ii for ii, word in  enumerate(word_counts, 1)}\n",
        "mapped_reviews = []\n",
        "pbar = pyprind.ProgBar(len(df['review']),  title='Map reviews to ints')\n",
        "for review in df['review']:\n",
        "  mapped_reviews.append([word_to_int[word] for word in review.split()])\n",
        "  pbar.update()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting words occurrences\n",
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:05:21\n",
            "Map reviews to ints\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['the', 'and', 'a', 'of', 'to']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [##############################] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:03\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldLRLD8wulu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining same length sequences\n",
        "\n",
        "sequence_length=200\n",
        "sequences=np.zeros((len(mapped_reviews),sequence_length),dtype=int)\n",
        "for i,row in enumerate(mapped_reviews):\n",
        "  review_arr=np.array(row)\n",
        "  sequences[i,-len(row):]=review_arr[-sequence_length:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVH8ibeCy15U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train=sequences[:25000,:]\n",
        "y_train=df.loc[:25000,\"sentiment\"].values\n",
        "X_test=sequences[25000:,:]\n",
        "y_test=df.loc[25000:,\"sentiment\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Fz3KVSzSnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123)\n",
        "\n",
        "#Function for mini-batch\n",
        "def create_batch_generator(x,y=None,batch_size=64):\n",
        "  n_batches=len(x)//batch_size\n",
        "  x=x[:n_batches*batch_size]\n",
        "  if y is not None:\n",
        "    y=y[:n_batches*batch_size]\n",
        "  for ii in range(0,len(x),batch_size):\n",
        "    if y is not None:\n",
        "      yield x[ii:ii+batch_size],y[ii:ii+batch_size]\n",
        "    else:\n",
        "      yield x[ii:ii+batch_size]\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_FMUNRK0fxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SentimentRNN(object):\n",
        "    def __init__(self,n_words,seq_len=200,\n",
        "                 lstm_size=256,num_layers=1,batch_size=64,\n",
        "                 learning_rate=0.0001,embed_size=200):\n",
        "        self.n_words=n_words\n",
        "        self.seq_len=seq_len\n",
        "        self.lstm_size=lstm_size            #number of hidden units\n",
        "        self.num_layers=num_layers\n",
        "        self.batch_size=batch_size\n",
        "        self.learning_rate=learning_rate\n",
        "        self.embed_size=embed_size\n",
        "\n",
        "        self.g= tf.Graph()\n",
        "        with self.g.as_default():\n",
        "            tf.set_random_seed(123)\n",
        "            self.build()\n",
        "            self.saver=tf.train.Saver()\n",
        "            self.init_op=tf.global_variables_initializer()\n",
        "\n",
        "    def build(self):\n",
        "\n",
        "        #defining placeholder\n",
        "        tf_x=tf.placeholder(tf.int32,shape=(self.batch_size,self.seq_len),name=\"tf_x\")\n",
        "        tf_y=tf.placeholder(tf.float32,shape=(self.batch_size),name=\"tf_y\")\n",
        "        tf_keepprob=tf.placeholder(tf.float32,name=\"tf_keepprob\")\n",
        "\n",
        "        #creating embeded layer\n",
        "        embedding=tf.Variable(tf.random_uniform((self.n_words,self.embed_size),minval=-1,maxval=1),name=\"embedding\")\n",
        "        embed_x=tf.nn.embedding_lookup(embedding,tf_x,name=\"embeded_x\")\n",
        "\n",
        "        #Define LSTM cell and stack them together\n",
        "        cells=tf.contrib.rnn.MultiRNNCell(\n",
        "            [tf.contrib.rnn.DropoutWrapper(\n",
        "                tf.contrib.rnn.BasicLSTMCell(self.lstm_size),output_keep_prob=tf_keepprob)\n",
        "                for i in range(self.num_layers)\n",
        "            ])\n",
        "        ##Define Initial State\n",
        "        self.initial_state=cells.zero_state(self.batch_size,tf.float32)\n",
        "        print(\" << initial state >> \",self.initial_state)\n",
        "\n",
        "        lstm_output,self.final_state=tf.nn.dynamic_rnn(cells,embed_x,initial_state=self.initial_state)\n",
        "\n",
        "        #   NOTE: LSTM Output Shape:\n",
        "        #   [batch_size,max time,cells.output_size]\n",
        "        print(\" << lstm_output >> \",lstm_output)\n",
        "        print(\" << final state >> \",self.final_state)\n",
        "\n",
        "        logits=tf.layers.dense(inputs=lstm_output[:,-1],\n",
        "                               units=1,activation=None,name=\"logits\")\n",
        "        logits=tf.squeeze(logits,name=\"logits_squeezed\")\n",
        "\n",
        "        print(\" << logits >> \",logits)\n",
        "        y_proba=tf.nn.sigmoid(logits,name=\"probabilities\")\n",
        "\n",
        "        predictions={\n",
        "            \"probabilities\":y_proba,\n",
        "            \"labels\":tf.cast(tf.round(y_proba),tf.int32,name=\"labels\")\n",
        "        }\n",
        "        print(\" << predictions >> \",predictions)\n",
        "\n",
        "        #Define cost Function\n",
        "        cost=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_y,logits=logits),name=\"cost\")\n",
        "\n",
        "        #Define Optimizer\n",
        "        optimizer=tf.train.AdamOptimizer(self.learning_rate)\n",
        "        train_op=optimizer.minimize(cost,name=\"train_op\")\n",
        "\n",
        "    def train(self,X_train,y_train,num_epochs):\n",
        "        with tf.Session(graph=self.g) as sess:\n",
        "            sess.run(self.init_op)\n",
        "            iteration=1\n",
        "            for epochs in range(num_epochs):\n",
        "                state=sess.run(self.initial_state)\n",
        "\n",
        "                for batch_x,batch_y in create_batch_generator(X_train,y_train,self.batch_size):\n",
        "                    feed={\"tf_x:0\":batch_x,\n",
        "                          \"tf_y:0\":batch_y,\n",
        "                          \"tf_keepprob:0\":0.5,\n",
        "                          self.initial_state:state}\n",
        "                    loss,_,state=sess.run([\"cost:0\",\"train_op\",self.final_state],feed_dict=feed)\n",
        "\n",
        "                    if iteration%20==0:\n",
        "                        print(\"Epoch : %d/%d Iteration : %d  | Train Loss : %7.5f\"%(epochs+1,num_epochs,iteration,loss))\n",
        "\n",
        "                    iteration+=1\n",
        "                if(epochs%10==0):\n",
        "                    self.saver.save(sess,\"model/sentiment-%d.ckpt\"%epochs)\n",
        "\n",
        "    def predict(self,X_data,return_prob=False):\n",
        "        preds=[]\n",
        "        with tf.Session(graph=self.g) as sess:\n",
        "            self.saver.restore(sess,tf.train.latest_checkpoint(\"./model/\"))\n",
        "            test_state=sess.run(self.initial_state)\n",
        "            for ii,batch_x in enumerate(create_batch_generator(X_data,None,batch_size=self.batch_size),1):\n",
        "                feed={\"tf_x:0\":batch_x,\n",
        "                      \"tf_keepprob:0\":1.0,\n",
        "                      self.initial_state:test_state}\n",
        "                if return_prob:\n",
        "                    pred,test_state=sess.run([\"probabilities:0\",self.final_state],feed_dict=feed)\n",
        "                else:\n",
        "                    pred,test_state=sess.run([\"labels:0\",self.final_state],feed_dict=feed)\n",
        "                preds.append(pred)\n",
        "\n",
        "        return np.concatenate(preds)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIzw6W7vfdvI",
        "colab_type": "code",
        "outputId": "3ba9a290-0f3e-4ab6-db49-fc521d1156fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "n_words=max(list(word_to_int.values()))+1\n",
        "rnn=SentimentRNN(n_words=n_words,\n",
        "                seq_len=sequence_length,\n",
        "                embed_size=256,\n",
        "                lstm_size=128,\n",
        "                num_layers=1,\n",
        "                batch_size=100,\n",
        "                learning_rate=0.001)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-8-8fdb60491642>:36: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-8-8fdb60491642>:36: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            " << initial state >>  (LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(100, 128) dtype=float32>),)\n",
            "WARNING:tensorflow:From <ipython-input-8-8fdb60491642>:42: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            " << lstm_output >>  Tensor(\"rnn/transpose_1:0\", shape=(100, 200, 128), dtype=float32)\n",
            " << final state >>  (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(100, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(100, 128) dtype=float32>),)\n",
            "WARNING:tensorflow:From <ipython-input-8-8fdb60491642>:50: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            " << logits >>  Tensor(\"logits_squeezed:0\", shape=(100,), dtype=float32)\n",
            " << predictions >>  {'probabilities': <tf.Tensor 'probabilities:0' shape=(100,) dtype=float32>, 'labels': <tf.Tensor 'labels:0' shape=(100,) dtype=int32>}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QipWie2ggg_X",
        "colab_type": "code",
        "outputId": "b2114cf6-6f29-4f74-fcbc-92f9eba73fea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8517
        }
      },
      "source": [
        "rnn.train(X_train,y_train,num_epochs=40)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1/40 Iteration : 20  | Train Loss : 0.00024\n",
            "Epoch : 1/40 Iteration : 40  | Train Loss : 0.00009\n",
            "Epoch : 1/40 Iteration : 60  | Train Loss : 0.00006\n",
            "Epoch : 1/40 Iteration : 80  | Train Loss : 0.00005\n",
            "Epoch : 1/40 Iteration : 100  | Train Loss : 0.00004\n",
            "Epoch : 1/40 Iteration : 120  | Train Loss : 0.00003\n",
            "Epoch : 1/40 Iteration : 140  | Train Loss : 1.71319\n",
            "Epoch : 1/40 Iteration : 160  | Train Loss : 0.03230\n",
            "Epoch : 1/40 Iteration : 180  | Train Loss : 0.01159\n",
            "Epoch : 1/40 Iteration : 200  | Train Loss : 0.01352\n",
            "Epoch : 1/40 Iteration : 220  | Train Loss : 0.01306\n",
            "Epoch : 1/40 Iteration : 240  | Train Loss : 0.01417\n",
            "Epoch : 2/40 Iteration : 260  | Train Loss : 3.49436\n",
            "Epoch : 2/40 Iteration : 280  | Train Loss : 0.99158\n",
            "Epoch : 2/40 Iteration : 300  | Train Loss : 0.34082\n",
            "Epoch : 2/40 Iteration : 320  | Train Loss : 0.14943\n",
            "Epoch : 2/40 Iteration : 340  | Train Loss : 0.08856\n",
            "Epoch : 2/40 Iteration : 360  | Train Loss : 0.06205\n",
            "Epoch : 2/40 Iteration : 380  | Train Loss : 2.97360\n",
            "Epoch : 2/40 Iteration : 400  | Train Loss : 1.11406\n",
            "Epoch : 2/40 Iteration : 420  | Train Loss : 0.51988\n",
            "Epoch : 2/40 Iteration : 440  | Train Loss : 0.29651\n",
            "Epoch : 2/40 Iteration : 460  | Train Loss : 0.21706\n",
            "Epoch : 2/40 Iteration : 480  | Train Loss : 0.14156\n",
            "Epoch : 2/40 Iteration : 500  | Train Loss : 0.11243\n",
            "Epoch : 3/40 Iteration : 520  | Train Loss : 1.44866\n",
            "Epoch : 3/40 Iteration : 540  | Train Loss : 0.76916\n",
            "Epoch : 3/40 Iteration : 560  | Train Loss : 0.44411\n",
            "Epoch : 3/40 Iteration : 580  | Train Loss : 0.28569\n",
            "Epoch : 3/40 Iteration : 600  | Train Loss : 0.19211\n",
            "Epoch : 3/40 Iteration : 620  | Train Loss : 0.14752\n",
            "Epoch : 3/40 Iteration : 640  | Train Loss : 1.49378\n",
            "Epoch : 3/40 Iteration : 660  | Train Loss : 0.84715\n",
            "Epoch : 3/40 Iteration : 680  | Train Loss : 0.55321\n",
            "Epoch : 3/40 Iteration : 700  | Train Loss : 0.38963\n",
            "Epoch : 3/40 Iteration : 720  | Train Loss : 0.27504\n",
            "Epoch : 3/40 Iteration : 740  | Train Loss : 0.19422\n",
            "Epoch : 4/40 Iteration : 760  | Train Loss : 1.61715\n",
            "Epoch : 4/40 Iteration : 780  | Train Loss : 0.94780\n",
            "Epoch : 4/40 Iteration : 800  | Train Loss : 0.62582\n",
            "Epoch : 4/40 Iteration : 820  | Train Loss : 0.41057\n",
            "Epoch : 4/40 Iteration : 840  | Train Loss : 0.27603\n",
            "Epoch : 4/40 Iteration : 860  | Train Loss : 0.16008\n",
            "Epoch : 4/40 Iteration : 880  | Train Loss : 1.73304\n",
            "Epoch : 4/40 Iteration : 900  | Train Loss : 0.94765\n",
            "Epoch : 4/40 Iteration : 920  | Train Loss : 0.55398\n",
            "Epoch : 4/40 Iteration : 940  | Train Loss : 0.25013\n",
            "Epoch : 4/40 Iteration : 960  | Train Loss : 0.09337\n",
            "Epoch : 4/40 Iteration : 980  | Train Loss : 0.00964\n",
            "Epoch : 4/40 Iteration : 1000  | Train Loss : 0.00275\n",
            "Epoch : 5/40 Iteration : 1020  | Train Loss : 0.10715\n",
            "Epoch : 5/40 Iteration : 1040  | Train Loss : 0.02367\n",
            "Epoch : 5/40 Iteration : 1060  | Train Loss : 0.01308\n",
            "Epoch : 5/40 Iteration : 1080  | Train Loss : 0.00834\n",
            "Epoch : 5/40 Iteration : 1100  | Train Loss : 0.00640\n",
            "Epoch : 5/40 Iteration : 1120  | Train Loss : 0.00625\n",
            "Epoch : 5/40 Iteration : 1140  | Train Loss : 0.78444\n",
            "Epoch : 5/40 Iteration : 1160  | Train Loss : 0.04073\n",
            "Epoch : 5/40 Iteration : 1180  | Train Loss : 0.01873\n",
            "Epoch : 5/40 Iteration : 1200  | Train Loss : 0.01422\n",
            "Epoch : 5/40 Iteration : 1220  | Train Loss : 0.01107\n",
            "Epoch : 5/40 Iteration : 1240  | Train Loss : 0.01127\n",
            "Epoch : 6/40 Iteration : 1260  | Train Loss : 3.06751\n",
            "Epoch : 6/40 Iteration : 1280  | Train Loss : 0.37429\n",
            "Epoch : 6/40 Iteration : 1300  | Train Loss : 0.16892\n",
            "Epoch : 6/40 Iteration : 1320  | Train Loss : 0.10140\n",
            "Epoch : 6/40 Iteration : 1340  | Train Loss : 0.06721\n",
            "Epoch : 6/40 Iteration : 1360  | Train Loss : 0.04954\n",
            "Epoch : 6/40 Iteration : 1380  | Train Loss : 2.96478\n",
            "Epoch : 6/40 Iteration : 1400  | Train Loss : 1.11229\n",
            "Epoch : 6/40 Iteration : 1420  | Train Loss : 0.51470\n",
            "Epoch : 6/40 Iteration : 1440  | Train Loss : 0.27405\n",
            "Epoch : 6/40 Iteration : 1460  | Train Loss : 0.18544\n",
            "Epoch : 6/40 Iteration : 1480  | Train Loss : 0.13045\n",
            "Epoch : 6/40 Iteration : 1500  | Train Loss : 0.09188\n",
            "Epoch : 7/40 Iteration : 1520  | Train Loss : 1.19809\n",
            "Epoch : 7/40 Iteration : 1540  | Train Loss : 0.63856\n",
            "Epoch : 7/40 Iteration : 1560  | Train Loss : 0.37438\n",
            "Epoch : 7/40 Iteration : 1580  | Train Loss : 0.31656\n",
            "Epoch : 7/40 Iteration : 1600  | Train Loss : 0.22285\n",
            "Epoch : 7/40 Iteration : 1620  | Train Loss : 0.17260\n",
            "Epoch : 7/40 Iteration : 1640  | Train Loss : 1.19626\n",
            "Epoch : 7/40 Iteration : 1660  | Train Loss : 0.67611\n",
            "Epoch : 7/40 Iteration : 1680  | Train Loss : 0.52246\n",
            "Epoch : 7/40 Iteration : 1700  | Train Loss : 0.34623\n",
            "Epoch : 7/40 Iteration : 1720  | Train Loss : 0.23001\n",
            "Epoch : 7/40 Iteration : 1740  | Train Loss : 0.14432\n",
            "Epoch : 8/40 Iteration : 1760  | Train Loss : 1.34158\n",
            "Epoch : 8/40 Iteration : 1780  | Train Loss : 0.72100\n",
            "Epoch : 8/40 Iteration : 1800  | Train Loss : 0.56309\n",
            "Epoch : 8/40 Iteration : 1820  | Train Loss : 0.44969\n",
            "Epoch : 8/40 Iteration : 1840  | Train Loss : 0.32538\n",
            "Epoch : 8/40 Iteration : 1860  | Train Loss : 0.23282\n",
            "Epoch : 8/40 Iteration : 1880  | Train Loss : 1.07286\n",
            "Epoch : 8/40 Iteration : 1900  | Train Loss : 0.77588\n",
            "Epoch : 8/40 Iteration : 1920  | Train Loss : 0.63278\n",
            "Epoch : 8/40 Iteration : 1940  | Train Loss : 0.41863\n",
            "Epoch : 8/40 Iteration : 1960  | Train Loss : 0.31173\n",
            "Epoch : 8/40 Iteration : 1980  | Train Loss : 0.29260\n",
            "Epoch : 8/40 Iteration : 2000  | Train Loss : 0.23342\n",
            "Epoch : 9/40 Iteration : 2020  | Train Loss : 0.86581\n",
            "Epoch : 9/40 Iteration : 2040  | Train Loss : 0.54087\n",
            "Epoch : 9/40 Iteration : 2060  | Train Loss : 0.35863\n",
            "Epoch : 9/40 Iteration : 2080  | Train Loss : 0.36435\n",
            "Epoch : 9/40 Iteration : 2100  | Train Loss : 0.26939\n",
            "Epoch : 9/40 Iteration : 2120  | Train Loss : 0.22954\n",
            "Epoch : 9/40 Iteration : 2140  | Train Loss : 0.80318\n",
            "Epoch : 9/40 Iteration : 2160  | Train Loss : 0.57067\n",
            "Epoch : 9/40 Iteration : 2180  | Train Loss : 0.52629\n",
            "Epoch : 9/40 Iteration : 2200  | Train Loss : 0.36608\n",
            "Epoch : 9/40 Iteration : 2220  | Train Loss : 0.24894\n",
            "Epoch : 9/40 Iteration : 2240  | Train Loss : 0.19913\n",
            "Epoch : 10/40 Iteration : 2260  | Train Loss : 0.96075\n",
            "Epoch : 10/40 Iteration : 2280  | Train Loss : 0.61603\n",
            "Epoch : 10/40 Iteration : 2300  | Train Loss : 0.51295\n",
            "Epoch : 10/40 Iteration : 2320  | Train Loss : 0.41335\n",
            "Epoch : 10/40 Iteration : 2340  | Train Loss : 0.27752\n",
            "Epoch : 10/40 Iteration : 2360  | Train Loss : 0.21142\n",
            "Epoch : 10/40 Iteration : 2380  | Train Loss : 0.92370\n",
            "Epoch : 10/40 Iteration : 2400  | Train Loss : 0.62319\n",
            "Epoch : 10/40 Iteration : 2420  | Train Loss : 0.49416\n",
            "Epoch : 10/40 Iteration : 2440  | Train Loss : 0.35465\n",
            "Epoch : 10/40 Iteration : 2460  | Train Loss : 0.25901\n",
            "Epoch : 10/40 Iteration : 2480  | Train Loss : 0.25579\n",
            "Epoch : 10/40 Iteration : 2500  | Train Loss : 0.13624\n",
            "Epoch : 11/40 Iteration : 2520  | Train Loss : 0.65109\n",
            "Epoch : 11/40 Iteration : 2540  | Train Loss : 0.42627\n",
            "Epoch : 11/40 Iteration : 2560  | Train Loss : 0.25553\n",
            "Epoch : 11/40 Iteration : 2580  | Train Loss : 0.28180\n",
            "Epoch : 11/40 Iteration : 2600  | Train Loss : 0.20480\n",
            "Epoch : 11/40 Iteration : 2620  | Train Loss : 0.13633\n",
            "Epoch : 11/40 Iteration : 2640  | Train Loss : 0.69750\n",
            "Epoch : 11/40 Iteration : 2660  | Train Loss : 0.44615\n",
            "Epoch : 11/40 Iteration : 2680  | Train Loss : 0.39593\n",
            "Epoch : 11/40 Iteration : 2700  | Train Loss : 0.27613\n",
            "Epoch : 11/40 Iteration : 2720  | Train Loss : 0.15474\n",
            "Epoch : 11/40 Iteration : 2740  | Train Loss : 0.10739\n",
            "Epoch : 12/40 Iteration : 2760  | Train Loss : 0.79313\n",
            "Epoch : 12/40 Iteration : 2780  | Train Loss : 0.40950\n",
            "Epoch : 12/40 Iteration : 2800  | Train Loss : 0.38880\n",
            "Epoch : 12/40 Iteration : 2820  | Train Loss : 0.33552\n",
            "Epoch : 12/40 Iteration : 2840  | Train Loss : 0.21264\n",
            "Epoch : 12/40 Iteration : 2860  | Train Loss : 0.16954\n",
            "Epoch : 12/40 Iteration : 2880  | Train Loss : 0.86854\n",
            "Epoch : 12/40 Iteration : 2900  | Train Loss : 0.51597\n",
            "Epoch : 12/40 Iteration : 2920  | Train Loss : 0.35701\n",
            "Epoch : 12/40 Iteration : 2940  | Train Loss : 0.26133\n",
            "Epoch : 12/40 Iteration : 2960  | Train Loss : 0.18929\n",
            "Epoch : 12/40 Iteration : 2980  | Train Loss : 0.18013\n",
            "Epoch : 12/40 Iteration : 3000  | Train Loss : 0.08717\n",
            "Epoch : 13/40 Iteration : 3020  | Train Loss : 0.52747\n",
            "Epoch : 13/40 Iteration : 3040  | Train Loss : 0.33832\n",
            "Epoch : 13/40 Iteration : 3060  | Train Loss : 0.20041\n",
            "Epoch : 13/40 Iteration : 3080  | Train Loss : 0.23479\n",
            "Epoch : 13/40 Iteration : 3100  | Train Loss : 0.18376\n",
            "Epoch : 13/40 Iteration : 3120  | Train Loss : 0.09798\n",
            "Epoch : 13/40 Iteration : 3140  | Train Loss : 0.58001\n",
            "Epoch : 13/40 Iteration : 3160  | Train Loss : 0.32704\n",
            "Epoch : 13/40 Iteration : 3180  | Train Loss : 0.32487\n",
            "Epoch : 13/40 Iteration : 3200  | Train Loss : 0.21413\n",
            "Epoch : 13/40 Iteration : 3220  | Train Loss : 0.11215\n",
            "Epoch : 13/40 Iteration : 3240  | Train Loss : 0.08060\n",
            "Epoch : 14/40 Iteration : 3260  | Train Loss : 0.66728\n",
            "Epoch : 14/40 Iteration : 3280  | Train Loss : 0.40057\n",
            "Epoch : 14/40 Iteration : 3300  | Train Loss : 0.35620\n",
            "Epoch : 14/40 Iteration : 3320  | Train Loss : 0.29052\n",
            "Epoch : 14/40 Iteration : 3340  | Train Loss : 0.19909\n",
            "Epoch : 14/40 Iteration : 3360  | Train Loss : 0.15659\n",
            "Epoch : 14/40 Iteration : 3380  | Train Loss : 0.63416\n",
            "Epoch : 14/40 Iteration : 3400  | Train Loss : 0.42900\n",
            "Epoch : 14/40 Iteration : 3420  | Train Loss : 0.27294\n",
            "Epoch : 14/40 Iteration : 3440  | Train Loss : 0.20690\n",
            "Epoch : 14/40 Iteration : 3460  | Train Loss : 0.12126\n",
            "Epoch : 14/40 Iteration : 3480  | Train Loss : 0.13789\n",
            "Epoch : 14/40 Iteration : 3500  | Train Loss : 0.10244\n",
            "Epoch : 15/40 Iteration : 3520  | Train Loss : 0.50116\n",
            "Epoch : 15/40 Iteration : 3540  | Train Loss : 0.28297\n",
            "Epoch : 15/40 Iteration : 3560  | Train Loss : 0.16159\n",
            "Epoch : 15/40 Iteration : 3580  | Train Loss : 0.20127\n",
            "Epoch : 15/40 Iteration : 3600  | Train Loss : 0.14232\n",
            "Epoch : 15/40 Iteration : 3620  | Train Loss : 0.08936\n",
            "Epoch : 15/40 Iteration : 3640  | Train Loss : 0.45175\n",
            "Epoch : 15/40 Iteration : 3660  | Train Loss : 0.25543\n",
            "Epoch : 15/40 Iteration : 3680  | Train Loss : 0.24799\n",
            "Epoch : 15/40 Iteration : 3700  | Train Loss : 0.17015\n",
            "Epoch : 15/40 Iteration : 3720  | Train Loss : 0.08255\n",
            "Epoch : 15/40 Iteration : 3740  | Train Loss : 0.07747\n",
            "Epoch : 16/40 Iteration : 3760  | Train Loss : 0.45852\n",
            "Epoch : 16/40 Iteration : 3780  | Train Loss : 0.28352\n",
            "Epoch : 16/40 Iteration : 3800  | Train Loss : 0.26907\n",
            "Epoch : 16/40 Iteration : 3820  | Train Loss : 0.21181\n",
            "Epoch : 16/40 Iteration : 3840  | Train Loss : 0.14851\n",
            "Epoch : 16/40 Iteration : 3860  | Train Loss : 0.09133\n",
            "Epoch : 16/40 Iteration : 3880  | Train Loss : 0.47662\n",
            "Epoch : 16/40 Iteration : 3900  | Train Loss : 0.31515\n",
            "Epoch : 16/40 Iteration : 3920  | Train Loss : 0.15739\n",
            "Epoch : 16/40 Iteration : 3940  | Train Loss : 0.12397\n",
            "Epoch : 16/40 Iteration : 3960  | Train Loss : 0.06027\n",
            "Epoch : 16/40 Iteration : 3980  | Train Loss : 0.07779\n",
            "Epoch : 16/40 Iteration : 4000  | Train Loss : 0.04633\n",
            "Epoch : 17/40 Iteration : 4020  | Train Loss : 0.36298\n",
            "Epoch : 17/40 Iteration : 4040  | Train Loss : 0.18844\n",
            "Epoch : 17/40 Iteration : 4060  | Train Loss : 0.12102\n",
            "Epoch : 17/40 Iteration : 4080  | Train Loss : 0.14041\n",
            "Epoch : 17/40 Iteration : 4100  | Train Loss : 0.07967\n",
            "Epoch : 17/40 Iteration : 4120  | Train Loss : 0.07014\n",
            "Epoch : 17/40 Iteration : 4140  | Train Loss : 0.29018\n",
            "Epoch : 17/40 Iteration : 4160  | Train Loss : 0.15361\n",
            "Epoch : 17/40 Iteration : 4180  | Train Loss : 0.18004\n",
            "Epoch : 17/40 Iteration : 4200  | Train Loss : 0.09393\n",
            "Epoch : 17/40 Iteration : 4220  | Train Loss : 0.04551\n",
            "Epoch : 17/40 Iteration : 4240  | Train Loss : 0.05939\n",
            "Epoch : 18/40 Iteration : 4260  | Train Loss : 0.29868\n",
            "Epoch : 18/40 Iteration : 4280  | Train Loss : 0.13407\n",
            "Epoch : 18/40 Iteration : 4300  | Train Loss : 0.21746\n",
            "Epoch : 18/40 Iteration : 4320  | Train Loss : 0.16561\n",
            "Epoch : 18/40 Iteration : 4340  | Train Loss : 0.08028\n",
            "Epoch : 18/40 Iteration : 4360  | Train Loss : 0.08055\n",
            "Epoch : 18/40 Iteration : 4380  | Train Loss : 0.31942\n",
            "Epoch : 18/40 Iteration : 4400  | Train Loss : 0.20699\n",
            "Epoch : 18/40 Iteration : 4420  | Train Loss : 0.08405\n",
            "Epoch : 18/40 Iteration : 4440  | Train Loss : 0.05517\n",
            "Epoch : 18/40 Iteration : 4460  | Train Loss : 0.02628\n",
            "Epoch : 18/40 Iteration : 4480  | Train Loss : 0.03529\n",
            "Epoch : 18/40 Iteration : 4500  | Train Loss : 0.01342\n",
            "Epoch : 19/40 Iteration : 4520  | Train Loss : 0.23424\n",
            "Epoch : 19/40 Iteration : 4540  | Train Loss : 0.12889\n",
            "Epoch : 19/40 Iteration : 4560  | Train Loss : 0.06833\n",
            "Epoch : 19/40 Iteration : 4580  | Train Loss : 0.05756\n",
            "Epoch : 19/40 Iteration : 4600  | Train Loss : 0.03513\n",
            "Epoch : 19/40 Iteration : 4620  | Train Loss : 0.03469\n",
            "Epoch : 19/40 Iteration : 4640  | Train Loss : 0.20004\n",
            "Epoch : 19/40 Iteration : 4660  | Train Loss : 0.07019\n",
            "Epoch : 19/40 Iteration : 4680  | Train Loss : 0.11189\n",
            "Epoch : 19/40 Iteration : 4700  | Train Loss : 0.04882\n",
            "Epoch : 19/40 Iteration : 4720  | Train Loss : 0.01385\n",
            "Epoch : 19/40 Iteration : 4740  | Train Loss : 0.03164\n",
            "Epoch : 20/40 Iteration : 4760  | Train Loss : 0.26596\n",
            "Epoch : 20/40 Iteration : 4780  | Train Loss : 0.09805\n",
            "Epoch : 20/40 Iteration : 4800  | Train Loss : 0.14177\n",
            "Epoch : 20/40 Iteration : 4820  | Train Loss : 0.08720\n",
            "Epoch : 20/40 Iteration : 4840  | Train Loss : 0.03594\n",
            "Epoch : 20/40 Iteration : 4860  | Train Loss : 0.03836\n",
            "Epoch : 20/40 Iteration : 4880  | Train Loss : 0.23943\n",
            "Epoch : 20/40 Iteration : 4900  | Train Loss : 0.11596\n",
            "Epoch : 20/40 Iteration : 4920  | Train Loss : 0.02901\n",
            "Epoch : 20/40 Iteration : 4940  | Train Loss : 0.03488\n",
            "Epoch : 20/40 Iteration : 4960  | Train Loss : 0.01605\n",
            "Epoch : 20/40 Iteration : 4980  | Train Loss : 0.02488\n",
            "Epoch : 20/40 Iteration : 5000  | Train Loss : 0.01484\n",
            "Epoch : 21/40 Iteration : 5020  | Train Loss : 0.08786\n",
            "Epoch : 21/40 Iteration : 5040  | Train Loss : 0.09518\n",
            "Epoch : 21/40 Iteration : 5060  | Train Loss : 0.04004\n",
            "Epoch : 21/40 Iteration : 5080  | Train Loss : 0.06842\n",
            "Epoch : 21/40 Iteration : 5100  | Train Loss : 0.02925\n",
            "Epoch : 21/40 Iteration : 5120  | Train Loss : 0.01753\n",
            "Epoch : 21/40 Iteration : 5140  | Train Loss : 0.11676\n",
            "Epoch : 21/40 Iteration : 5160  | Train Loss : 0.04151\n",
            "Epoch : 21/40 Iteration : 5180  | Train Loss : 0.04856\n",
            "Epoch : 21/40 Iteration : 5200  | Train Loss : 0.02735\n",
            "Epoch : 21/40 Iteration : 5220  | Train Loss : 0.00925\n",
            "Epoch : 21/40 Iteration : 5240  | Train Loss : 0.01201\n",
            "Epoch : 22/40 Iteration : 5260  | Train Loss : 0.21150\n",
            "Epoch : 22/40 Iteration : 5280  | Train Loss : 0.07071\n",
            "Epoch : 22/40 Iteration : 5300  | Train Loss : 0.12570\n",
            "Epoch : 22/40 Iteration : 5320  | Train Loss : 0.07498\n",
            "Epoch : 22/40 Iteration : 5340  | Train Loss : 0.03908\n",
            "Epoch : 22/40 Iteration : 5360  | Train Loss : 0.03220\n",
            "Epoch : 22/40 Iteration : 5380  | Train Loss : 0.17599\n",
            "Epoch : 22/40 Iteration : 5400  | Train Loss : 0.08044\n",
            "Epoch : 22/40 Iteration : 5420  | Train Loss : 0.01424\n",
            "Epoch : 22/40 Iteration : 5440  | Train Loss : 0.02852\n",
            "Epoch : 22/40 Iteration : 5460  | Train Loss : 0.01562\n",
            "Epoch : 22/40 Iteration : 5480  | Train Loss : 0.01435\n",
            "Epoch : 22/40 Iteration : 5500  | Train Loss : 0.00778\n",
            "Epoch : 23/40 Iteration : 5520  | Train Loss : 0.08923\n",
            "Epoch : 23/40 Iteration : 5540  | Train Loss : 0.03849\n",
            "Epoch : 23/40 Iteration : 5560  | Train Loss : 0.02222\n",
            "Epoch : 23/40 Iteration : 5580  | Train Loss : 0.02535\n",
            "Epoch : 23/40 Iteration : 5600  | Train Loss : 0.01599\n",
            "Epoch : 23/40 Iteration : 5620  | Train Loss : 0.02610\n",
            "Epoch : 23/40 Iteration : 5640  | Train Loss : 0.10114\n",
            "Epoch : 23/40 Iteration : 5660  | Train Loss : 0.03464\n",
            "Epoch : 23/40 Iteration : 5680  | Train Loss : 0.06443\n",
            "Epoch : 23/40 Iteration : 5700  | Train Loss : 0.02653\n",
            "Epoch : 23/40 Iteration : 5720  | Train Loss : 0.01273\n",
            "Epoch : 23/40 Iteration : 5740  | Train Loss : 0.01837\n",
            "Epoch : 24/40 Iteration : 5760  | Train Loss : 0.11440\n",
            "Epoch : 24/40 Iteration : 5780  | Train Loss : 0.06939\n",
            "Epoch : 24/40 Iteration : 5800  | Train Loss : 0.11084\n",
            "Epoch : 24/40 Iteration : 5820  | Train Loss : 0.03393\n",
            "Epoch : 24/40 Iteration : 5840  | Train Loss : 0.02347\n",
            "Epoch : 24/40 Iteration : 5860  | Train Loss : 0.03657\n",
            "Epoch : 24/40 Iteration : 5880  | Train Loss : 0.06172\n",
            "Epoch : 24/40 Iteration : 5900  | Train Loss : 0.11784\n",
            "Epoch : 24/40 Iteration : 5920  | Train Loss : 0.01661\n",
            "Epoch : 24/40 Iteration : 5940  | Train Loss : 0.01838\n",
            "Epoch : 24/40 Iteration : 5960  | Train Loss : 0.01664\n",
            "Epoch : 24/40 Iteration : 5980  | Train Loss : 0.00938\n",
            "Epoch : 24/40 Iteration : 6000  | Train Loss : 0.02308\n",
            "Epoch : 25/40 Iteration : 6020  | Train Loss : 0.08136\n",
            "Epoch : 25/40 Iteration : 6040  | Train Loss : 0.03427\n",
            "Epoch : 25/40 Iteration : 6060  | Train Loss : 0.01025\n",
            "Epoch : 25/40 Iteration : 6080  | Train Loss : 0.04713\n",
            "Epoch : 25/40 Iteration : 6100  | Train Loss : 0.00884\n",
            "Epoch : 25/40 Iteration : 6120  | Train Loss : 0.01412\n",
            "Epoch : 25/40 Iteration : 6140  | Train Loss : 0.05636\n",
            "Epoch : 25/40 Iteration : 6160  | Train Loss : 0.01116\n",
            "Epoch : 25/40 Iteration : 6180  | Train Loss : 0.04536\n",
            "Epoch : 25/40 Iteration : 6200  | Train Loss : 0.02202\n",
            "Epoch : 25/40 Iteration : 6220  | Train Loss : 0.01703\n",
            "Epoch : 25/40 Iteration : 6240  | Train Loss : 0.01016\n",
            "Epoch : 26/40 Iteration : 6260  | Train Loss : 0.08913\n",
            "Epoch : 26/40 Iteration : 6280  | Train Loss : 0.02381\n",
            "Epoch : 26/40 Iteration : 6300  | Train Loss : 0.05040\n",
            "Epoch : 26/40 Iteration : 6320  | Train Loss : 0.01949\n",
            "Epoch : 26/40 Iteration : 6340  | Train Loss : 0.01232\n",
            "Epoch : 26/40 Iteration : 6360  | Train Loss : 0.01355\n",
            "Epoch : 26/40 Iteration : 6380  | Train Loss : 0.04225\n",
            "Epoch : 26/40 Iteration : 6400  | Train Loss : 0.05550\n",
            "Epoch : 26/40 Iteration : 6420  | Train Loss : 0.01470\n",
            "Epoch : 26/40 Iteration : 6440  | Train Loss : 0.02357\n",
            "Epoch : 26/40 Iteration : 6460  | Train Loss : 0.00705\n",
            "Epoch : 26/40 Iteration : 6480  | Train Loss : 0.01053\n",
            "Epoch : 26/40 Iteration : 6500  | Train Loss : 0.01012\n",
            "Epoch : 27/40 Iteration : 6520  | Train Loss : 0.05662\n",
            "Epoch : 27/40 Iteration : 6540  | Train Loss : 0.05026\n",
            "Epoch : 27/40 Iteration : 6560  | Train Loss : 0.01068\n",
            "Epoch : 27/40 Iteration : 6580  | Train Loss : 0.01178\n",
            "Epoch : 27/40 Iteration : 6600  | Train Loss : 0.00923\n",
            "Epoch : 27/40 Iteration : 6620  | Train Loss : 0.00651\n",
            "Epoch : 27/40 Iteration : 6640  | Train Loss : 0.02965\n",
            "Epoch : 27/40 Iteration : 6660  | Train Loss : 0.00435\n",
            "Epoch : 27/40 Iteration : 6680  | Train Loss : 0.01922\n",
            "Epoch : 27/40 Iteration : 6700  | Train Loss : 0.01829\n",
            "Epoch : 27/40 Iteration : 6720  | Train Loss : 0.00668\n",
            "Epoch : 27/40 Iteration : 6740  | Train Loss : 0.01024\n",
            "Epoch : 28/40 Iteration : 6760  | Train Loss : 0.04028\n",
            "Epoch : 28/40 Iteration : 6780  | Train Loss : 0.02240\n",
            "Epoch : 28/40 Iteration : 6800  | Train Loss : 0.04137\n",
            "Epoch : 28/40 Iteration : 6820  | Train Loss : 0.01083\n",
            "Epoch : 28/40 Iteration : 6840  | Train Loss : 0.01018\n",
            "Epoch : 28/40 Iteration : 6860  | Train Loss : 0.00720\n",
            "Epoch : 28/40 Iteration : 6880  | Train Loss : 0.01043\n",
            "Epoch : 28/40 Iteration : 6900  | Train Loss : 0.02746\n",
            "Epoch : 28/40 Iteration : 6920  | Train Loss : 0.00468\n",
            "Epoch : 28/40 Iteration : 6940  | Train Loss : 0.01685\n",
            "Epoch : 28/40 Iteration : 6960  | Train Loss : 0.00578\n",
            "Epoch : 28/40 Iteration : 6980  | Train Loss : 0.01452\n",
            "Epoch : 28/40 Iteration : 7000  | Train Loss : 0.02680\n",
            "Epoch : 29/40 Iteration : 7020  | Train Loss : 0.03545\n",
            "Epoch : 29/40 Iteration : 7040  | Train Loss : 0.01188\n",
            "Epoch : 29/40 Iteration : 7060  | Train Loss : 0.00585\n",
            "Epoch : 29/40 Iteration : 7080  | Train Loss : 0.00495\n",
            "Epoch : 29/40 Iteration : 7100  | Train Loss : 0.01475\n",
            "Epoch : 29/40 Iteration : 7120  | Train Loss : 0.01017\n",
            "Epoch : 29/40 Iteration : 7140  | Train Loss : 0.01638\n",
            "Epoch : 29/40 Iteration : 7160  | Train Loss : 0.01304\n",
            "Epoch : 29/40 Iteration : 7180  | Train Loss : 0.00702\n",
            "Epoch : 29/40 Iteration : 7200  | Train Loss : 0.11684\n",
            "Epoch : 29/40 Iteration : 7220  | Train Loss : 0.02386\n",
            "Epoch : 29/40 Iteration : 7240  | Train Loss : 0.00489\n",
            "Epoch : 30/40 Iteration : 7260  | Train Loss : 0.02332\n",
            "Epoch : 30/40 Iteration : 7280  | Train Loss : 0.00582\n",
            "Epoch : 30/40 Iteration : 7300  | Train Loss : 0.02082\n",
            "Epoch : 30/40 Iteration : 7320  | Train Loss : 0.01149\n",
            "Epoch : 30/40 Iteration : 7340  | Train Loss : 0.02466\n",
            "Epoch : 30/40 Iteration : 7360  | Train Loss : 0.00670\n",
            "Epoch : 30/40 Iteration : 7380  | Train Loss : 0.00752\n",
            "Epoch : 30/40 Iteration : 7400  | Train Loss : 0.00775\n",
            "Epoch : 30/40 Iteration : 7420  | Train Loss : 0.01345\n",
            "Epoch : 30/40 Iteration : 7440  | Train Loss : 0.01186\n",
            "Epoch : 30/40 Iteration : 7460  | Train Loss : 0.03315\n",
            "Epoch : 30/40 Iteration : 7480  | Train Loss : 0.00322\n",
            "Epoch : 30/40 Iteration : 7500  | Train Loss : 0.01718\n",
            "Epoch : 31/40 Iteration : 7520  | Train Loss : 0.01101\n",
            "Epoch : 31/40 Iteration : 7540  | Train Loss : 0.01812\n",
            "Epoch : 31/40 Iteration : 7560  | Train Loss : 0.00563\n",
            "Epoch : 31/40 Iteration : 7580  | Train Loss : 0.00653\n",
            "Epoch : 31/40 Iteration : 7600  | Train Loss : 0.00266\n",
            "Epoch : 31/40 Iteration : 7620  | Train Loss : 0.03293\n",
            "Epoch : 31/40 Iteration : 7640  | Train Loss : 0.00992\n",
            "Epoch : 31/40 Iteration : 7660  | Train Loss : 0.00318\n",
            "Epoch : 31/40 Iteration : 7680  | Train Loss : 0.02425\n",
            "Epoch : 31/40 Iteration : 7700  | Train Loss : 0.00964\n",
            "Epoch : 31/40 Iteration : 7720  | Train Loss : 0.00052\n",
            "Epoch : 31/40 Iteration : 7740  | Train Loss : 0.00625\n",
            "Epoch : 32/40 Iteration : 7760  | Train Loss : 0.04924\n",
            "Epoch : 32/40 Iteration : 7780  | Train Loss : 0.00215\n",
            "Epoch : 32/40 Iteration : 7800  | Train Loss : 0.00826\n",
            "Epoch : 32/40 Iteration : 7820  | Train Loss : 0.01372\n",
            "Epoch : 32/40 Iteration : 7840  | Train Loss : 0.00393\n",
            "Epoch : 32/40 Iteration : 7860  | Train Loss : 0.00469\n",
            "Epoch : 32/40 Iteration : 7880  | Train Loss : 0.00782\n",
            "Epoch : 32/40 Iteration : 7900  | Train Loss : 0.01221\n",
            "Epoch : 32/40 Iteration : 7920  | Train Loss : 0.00242\n",
            "Epoch : 32/40 Iteration : 7940  | Train Loss : 0.01442\n",
            "Epoch : 32/40 Iteration : 7960  | Train Loss : 0.04370\n",
            "Epoch : 32/40 Iteration : 7980  | Train Loss : 0.00330\n",
            "Epoch : 32/40 Iteration : 8000  | Train Loss : 0.00193\n",
            "Epoch : 33/40 Iteration : 8020  | Train Loss : 0.00906\n",
            "Epoch : 33/40 Iteration : 8040  | Train Loss : 0.00371\n",
            "Epoch : 33/40 Iteration : 8060  | Train Loss : 0.00565\n",
            "Epoch : 33/40 Iteration : 8080  | Train Loss : 0.00708\n",
            "Epoch : 33/40 Iteration : 8100  | Train Loss : 0.00523\n",
            "Epoch : 33/40 Iteration : 8120  | Train Loss : 0.00464\n",
            "Epoch : 33/40 Iteration : 8140  | Train Loss : 0.01185\n",
            "Epoch : 33/40 Iteration : 8160  | Train Loss : 0.00285\n",
            "Epoch : 33/40 Iteration : 8180  | Train Loss : 0.00330\n",
            "Epoch : 33/40 Iteration : 8200  | Train Loss : 0.00303\n",
            "Epoch : 33/40 Iteration : 8220  | Train Loss : 0.00455\n",
            "Epoch : 33/40 Iteration : 8240  | Train Loss : 0.00642\n",
            "Epoch : 34/40 Iteration : 8260  | Train Loss : 0.01069\n",
            "Epoch : 34/40 Iteration : 8280  | Train Loss : 0.00722\n",
            "Epoch : 34/40 Iteration : 8300  | Train Loss : 0.00356\n",
            "Epoch : 34/40 Iteration : 8320  | Train Loss : 0.00597\n",
            "Epoch : 34/40 Iteration : 8340  | Train Loss : 0.00827\n",
            "Epoch : 34/40 Iteration : 8360  | Train Loss : 0.00177\n",
            "Epoch : 34/40 Iteration : 8380  | Train Loss : 0.00183\n",
            "Epoch : 34/40 Iteration : 8400  | Train Loss : 0.00146\n",
            "Epoch : 34/40 Iteration : 8420  | Train Loss : 0.00148\n",
            "Epoch : 34/40 Iteration : 8440  | Train Loss : 0.00136\n",
            "Epoch : 34/40 Iteration : 8460  | Train Loss : 0.00145\n",
            "Epoch : 34/40 Iteration : 8480  | Train Loss : 0.00326\n",
            "Epoch : 34/40 Iteration : 8500  | Train Loss : 0.00436\n",
            "Epoch : 35/40 Iteration : 8520  | Train Loss : 0.00225\n",
            "Epoch : 35/40 Iteration : 8540  | Train Loss : 0.00293\n",
            "Epoch : 35/40 Iteration : 8560  | Train Loss : 0.00098\n",
            "Epoch : 35/40 Iteration : 8580  | Train Loss : 0.00228\n",
            "Epoch : 35/40 Iteration : 8600  | Train Loss : 0.01280\n",
            "Epoch : 35/40 Iteration : 8620  | Train Loss : 0.00372\n",
            "Epoch : 35/40 Iteration : 8640  | Train Loss : 0.00394\n",
            "Epoch : 35/40 Iteration : 8660  | Train Loss : 0.00055\n",
            "Epoch : 35/40 Iteration : 8680  | Train Loss : 0.01253\n",
            "Epoch : 35/40 Iteration : 8700  | Train Loss : 0.00624\n",
            "Epoch : 35/40 Iteration : 8720  | Train Loss : 0.00273\n",
            "Epoch : 35/40 Iteration : 8740  | Train Loss : 0.00677\n",
            "Epoch : 36/40 Iteration : 8760  | Train Loss : 0.01769\n",
            "Epoch : 36/40 Iteration : 8780  | Train Loss : 0.00262\n",
            "Epoch : 36/40 Iteration : 8800  | Train Loss : 0.00807\n",
            "Epoch : 36/40 Iteration : 8820  | Train Loss : 0.00751\n",
            "Epoch : 36/40 Iteration : 8840  | Train Loss : 0.00121\n",
            "Epoch : 36/40 Iteration : 8860  | Train Loss : 0.00033\n",
            "Epoch : 36/40 Iteration : 8880  | Train Loss : 0.00280\n",
            "Epoch : 36/40 Iteration : 8900  | Train Loss : 0.00160\n",
            "Epoch : 36/40 Iteration : 8920  | Train Loss : 0.00080\n",
            "Epoch : 36/40 Iteration : 8940  | Train Loss : 0.00268\n",
            "Epoch : 36/40 Iteration : 8960  | Train Loss : 0.00345\n",
            "Epoch : 36/40 Iteration : 8980  | Train Loss : 0.00096\n",
            "Epoch : 36/40 Iteration : 9000  | Train Loss : 0.00228\n",
            "Epoch : 37/40 Iteration : 9020  | Train Loss : 0.01873\n",
            "Epoch : 37/40 Iteration : 9040  | Train Loss : 0.00349\n",
            "Epoch : 37/40 Iteration : 9060  | Train Loss : 0.00228\n",
            "Epoch : 37/40 Iteration : 9080  | Train Loss : 0.00074\n",
            "Epoch : 37/40 Iteration : 9100  | Train Loss : 0.00190\n",
            "Epoch : 37/40 Iteration : 9120  | Train Loss : 0.00401\n",
            "Epoch : 37/40 Iteration : 9140  | Train Loss : 0.00497\n",
            "Epoch : 37/40 Iteration : 9160  | Train Loss : 0.00050\n",
            "Epoch : 37/40 Iteration : 9180  | Train Loss : 0.04510\n",
            "Epoch : 37/40 Iteration : 9200  | Train Loss : 0.00468\n",
            "Epoch : 37/40 Iteration : 9220  | Train Loss : 0.00087\n",
            "Epoch : 37/40 Iteration : 9240  | Train Loss : 0.00597\n",
            "Epoch : 38/40 Iteration : 9260  | Train Loss : 0.00425\n",
            "Epoch : 38/40 Iteration : 9280  | Train Loss : 0.00179\n",
            "Epoch : 38/40 Iteration : 9300  | Train Loss : 0.00582\n",
            "Epoch : 38/40 Iteration : 9320  | Train Loss : 0.00202\n",
            "Epoch : 38/40 Iteration : 9340  | Train Loss : 0.00368\n",
            "Epoch : 38/40 Iteration : 9360  | Train Loss : 0.00493\n",
            "Epoch : 38/40 Iteration : 9380  | Train Loss : 0.00320\n",
            "Epoch : 38/40 Iteration : 9400  | Train Loss : 0.01242\n",
            "Epoch : 38/40 Iteration : 9420  | Train Loss : 0.00035\n",
            "Epoch : 38/40 Iteration : 9440  | Train Loss : 0.00148\n",
            "Epoch : 38/40 Iteration : 9460  | Train Loss : 0.00190\n",
            "Epoch : 38/40 Iteration : 9480  | Train Loss : 0.01845\n",
            "Epoch : 38/40 Iteration : 9500  | Train Loss : 0.00589\n",
            "Epoch : 39/40 Iteration : 9520  | Train Loss : 0.00353\n",
            "Epoch : 39/40 Iteration : 9540  | Train Loss : 0.02932\n",
            "Epoch : 39/40 Iteration : 9560  | Train Loss : 0.00139\n",
            "Epoch : 39/40 Iteration : 9580  | Train Loss : 0.00082\n",
            "Epoch : 39/40 Iteration : 9600  | Train Loss : 0.00222\n",
            "Epoch : 39/40 Iteration : 9620  | Train Loss : 0.00123\n",
            "Epoch : 39/40 Iteration : 9640  | Train Loss : 0.00308\n",
            "Epoch : 39/40 Iteration : 9660  | Train Loss : 0.00287\n",
            "Epoch : 39/40 Iteration : 9680  | Train Loss : 0.00623\n",
            "Epoch : 39/40 Iteration : 9700  | Train Loss : 0.00108\n",
            "Epoch : 39/40 Iteration : 9720  | Train Loss : 0.00489\n",
            "Epoch : 39/40 Iteration : 9740  | Train Loss : 0.01582\n",
            "Epoch : 40/40 Iteration : 9760  | Train Loss : 0.00280\n",
            "Epoch : 40/40 Iteration : 9780  | Train Loss : 0.01308\n",
            "Epoch : 40/40 Iteration : 9800  | Train Loss : 0.03040\n",
            "Epoch : 40/40 Iteration : 9820  | Train Loss : 0.00058\n",
            "Epoch : 40/40 Iteration : 9840  | Train Loss : 0.00285\n",
            "Epoch : 40/40 Iteration : 9860  | Train Loss : 0.03817\n",
            "Epoch : 40/40 Iteration : 9880  | Train Loss : 0.00086\n",
            "Epoch : 40/40 Iteration : 9900  | Train Loss : 0.00372\n",
            "Epoch : 40/40 Iteration : 9920  | Train Loss : 0.00657\n",
            "Epoch : 40/40 Iteration : 9940  | Train Loss : 0.00168\n",
            "Epoch : 40/40 Iteration : 9960  | Train Loss : 0.00050\n",
            "Epoch : 40/40 Iteration : 9980  | Train Loss : 0.00041\n",
            "Epoch : 40/40 Iteration : 10000  | Train Loss : 0.00444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG30S2C0hmrr",
        "colab_type": "code",
        "outputId": "212290d6-8011-4b01-e370-24301f3a9180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "pred=rnn.predict(X_test)\n",
        "y_true=y_test[:len(pred)]\n",
        "print(\"Test Accuracy : %.3f\"%(np.sum(y_true==pred)/len(y_true)))\n",
        "\n",
        "prob=rnn.predict(X_test,return_prob=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from ./model/sentiment-30.ckpt\n",
            "Test Accuracy : 0.697\n",
            "INFO:tensorflow:Restoring parameters from ./model/sentiment-30.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m45JiEmBtEf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}